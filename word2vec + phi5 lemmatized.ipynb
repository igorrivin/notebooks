{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.formatter import assemble_phi5_author_filepaths\n",
    "from cltk.corpus.utils.formatter import phi5_plaintext_cleanup\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.stop.latin.stops import STOPS_LIST\n",
    "from nltk.tokenize.punkt import PunktLanguageVars\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prepare PHI sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepaths = assemble_phi5_author_filepaths()\n",
    "filepaths = filepaths[:5]  # for testing\n",
    "sent_tokenizer = TokenizeSentence('latin')\n",
    "p = PunktLanguageVars()\n",
    "jv = JVReplacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi_sentences = []\n",
    "for filepath in filepaths:\n",
    "    with open(filepath) as f:\n",
    "        text_raw = f.read()\n",
    "    text_clean = phi5_plaintext_cleanup(text_raw)  # phi5_plaintext_cleanup()\n",
    "    sent_tokens_upper = sent_tokenizer.tokenize_sentences(text_clean)  # sentence tokenize\n",
    "    sent_tokens = [s.lower() for s in sent_tokens_upper]  # lowercase\n",
    "    #sentence_tokens_author = []\n",
    "    for sent in sent_tokens:  # tokenize words in sentences\n",
    "        sent_word_tokens = []\n",
    "        sent_word_tokens = p.word_tokenize(sent)\n",
    "        sent_word_tokens = [jv.replace(word) for word in sent_word_tokens]\n",
    "        sent_word_tokens_new = []\n",
    "        for word in sent_word_tokens:  # remove punctuation (final period, commas, etc)\n",
    "            if word[-1] in ['.', '“']:\n",
    "                word_new = word[:-1]\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            elif word[0] =='“':\n",
    "                word_new = word[1:]\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            elif word in [',', '.', ';', ':', '\"', \"'\", '?', '-', '!', '*', '[', ']', '{', '}', '!', '”']:\n",
    "                continue\n",
    "            elif word in STOPS_LIST:  # remove stops\n",
    "                continue\n",
    "            elif '˘' in word:  # rm meter\n",
    "                continue\n",
    "            elif 'á' in word:  # rm accents from vowels; find more graceful way of doing this\n",
    "                word_new = word.replace('á', 'a')\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            elif 'é' in word:\n",
    "                word_new = word.replace('é', 'e')\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            elif 'í' in word:\n",
    "                word_new = word.replace('í', 'i')\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            elif 'ó' in word: #! no 'ó' found in PHI5\n",
    "                word_new = word.replace('ó', 'o')\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "                print('rmd vowel', word, word_new)\n",
    "            elif 'ú' in word:\n",
    "                word_new = word.replace('ú', 'u')\n",
    "                sent_word_tokens_new.append(word_new)\n",
    "            else:\n",
    "                sent_word_tokens_new.append(word)\n",
    "        sent_word_tokens_new = [w for w in sent_word_tokens_new if len(w) > 1]  # rm short words\n",
    "\n",
    "        sentence = [w for w in sent_word_tokens_new if w]  # remove any empty words (created thru above cleanup)\n",
    "        if sentence:  # remove any empty sentences (created thru above cleanup)\n",
    "            phi_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['uerborum', 'ius', 'ciuile', 'pertinent', 'significatione', 'postliminio', 'reus', 'altero', 'litem', 'contestatam', 'habet', 'siue', 'egit', 'siue', 'eo', 'actum', 'est'], ['reus', 'stipulando', 'stipulator', 'dicitur', 'quippe', 'suo', 'nomine', 'altero', 'quid', 'stipulatus', 'alteri', 'adstipulatus', 'est'], ['reus', 'promittendo', 'suo', 'nomine', 'alteri', 'quid', 'promisit', 'altero', 'quid', 'promisit'], ['saltus', 'siluae', 'pastiones', 'sunt', 'quarum', 'causa', 'casae', 'quoque'], ['qua', 'particula', 'eo', 'saltu', 'pastorum', 'custodum', 'causa', 'aratur', 'ea', 'res', 'peremit', 'nomen', 'saltui', 'fundi', 'agro', 'culto', 'eius', 'causa', 'habet', 'aedificium', 'qua', 'particula', 'eo', 'habet', 'siluam']]\n",
      "Total sentences: 46042\n"
     ]
    }
   ],
   "source": [
    "print(phi_sentences[:5])\n",
    "print('Total sentences:', len(phi_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CLTK:Loading lemmata. This may take a minute.\n"
     ]
    }
   ],
   "source": [
    "# lemmatize sentences\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "\n",
    "phi_sentences_lemma = []\n",
    "for sentence in phi_sentences:\n",
    "    lemmatized_sent = lemmatizer.lemmatize(sentence)\n",
    "    phi_sentences_lemma.append(lemmatized_sent)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['verbum', 'jus', 'civile', 'pertineo', 'significatio', 'postliminium', 'reus', 'alter', 'lito', 'contestor', 'habeo', 'si', 'ago', 'si', 'eo1', 'ago', 'edo1'], ['reus', 'stipulo', 'stipulator', 'dico2', 'quippe', 'suo', 'nomen', 'alter', 'quis1', 'stipulo', 'alter', 'adstipulo', 'edo1'], ['reus', 'promitto', 'suo', 'nomen', 'alter', 'quis1', 'promitto', 'alter', 'quis1', 'promitto'], ['saltus1', 'silva', 'pastio', 'sum1', 'qui1', 'causa', 'cado', 'quoque'], ['qui1', 'particula', 'eo1', 'saltus1', 'pasco', 'custos', 'causa', 'aro', 'is', 'reor', 'per-emo', 'nomen', 'saltus1', 'fundo1', 'ager', 'colo1', 'is', 'causa', 'habeo', 'aedificium', 'qui1', 'particula', 'eo1', 'habeo', 'silva']]\n",
      "Total sentences: 46042\n"
     ]
    }
   ],
   "source": [
    "print(phi_sentences_lemma[:5])\n",
    "print('Total sentences:', len(phi_sentences_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=phi_sentences_lemma, size=100, window=5, min_count=5, workers=4)\n",
    "# If you’re finished training a model (=no more updates, only querying), you can do\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = os.path.expanduser('~/cltk_data/user_data/word2vec_phi_lemma.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(model_path)  # 84 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to load:\n",
    "model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xx', 0.769722580909729),\n",
       " ('duo', 0.7590145468711853),\n",
       " ('uter', 0.7507055997848511),\n",
       " ('xii', 0.7478469610214233),\n",
       " ('undecimus', 0.7446541786193848),\n",
       " ('hemitonium', 0.7335435152053833),\n",
       " ('circinatio', 0.7317605018615723),\n",
       " ('xxx', 0.7282785177230835),\n",
       " ('unus', 0.7280042767524719),\n",
       " ('cymatium', 0.7254071235656738)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('alter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sum1', 0.8618136644363403),\n",
       " ('ambulatio', 0.8575546741485596),\n",
       " ('mutulus', 0.8557659387588501),\n",
       " ('epistylium', 0.8400512933731079),\n",
       " ('fio', 0.835148811340332),\n",
       " ('denticulus', 0.8341249227523804),\n",
       " ('orbiculus', 0.8340144753456116),\n",
       " ('uto', 0.8300203084945679),\n",
       " ('influo', 0.8242273330688477),\n",
       " ('symmetria', 0.822694718837738)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('habeo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nauta', 0.9465115666389465),\n",
       " ('aequor', 0.9337424039840698),\n",
       " ('unda', 0.9327002167701721),\n",
       " ('undo', 0.9317194223403931),\n",
       " ('rupes', 0.9209202527999878),\n",
       " ('fluctus', 0.9206447601318359),\n",
       " ('amnis', 0.9127741456031799),\n",
       " ('libyen', 0.9100551605224609),\n",
       " ('fretus1', 0.90400230884552),\n",
       " ('boreas', 0.9012879729270935)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('pontus1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 0.9140404462814331),\n",
       " ('dirigo', 0.8806520700454712),\n",
       " ('ito', 0.8663041591644287),\n",
       " ('ambulatio', 0.8542487025260925),\n",
       " ('uto', 0.8472296595573425),\n",
       " ('sui', 0.8286542892456055),\n",
       " ('posticum', 0.8192173838615417),\n",
       " ('epistylium', 0.8109995722770691),\n",
       " ('paries', 0.8076523542404175),\n",
       " ('qui1', 0.8073225617408752)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('eo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('procedo', 0.8233951926231384),\n",
       " ('minito', 0.7950356006622314),\n",
       " ('fuga', 0.7927190065383911),\n",
       " ('fascis', 0.7914959788322449),\n",
       " ('relabor', 0.7890385389328003),\n",
       " ('ad-levo1', 0.7867715358734131),\n",
       " ('triumpho', 0.7811341881752014),\n",
       " ('speculor', 0.7683494091033936),\n",
       " ('concurro', 0.7673412561416626),\n",
       " ('euphraten', 0.7663215398788452)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('castra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conscius', 0.890749454498291),\n",
       " ('tristis', 0.8817610144615173),\n",
       " ('saevio', 0.8768550157546997),\n",
       " ('!”', 0.8750863075256348),\n",
       " ('parens', 0.8706927299499512),\n",
       " ('virginitas', 0.8700000047683716),\n",
       " ('casus1', 0.8685871362686157),\n",
       " ('en', 0.8672870993614197),\n",
       " ('ecquis', 0.8627985715866089),\n",
       " ('profugus', 0.8614393472671509)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conscius', 0.890749454498291),\n",
       " ('tristis', 0.8817610144615173),\n",
       " ('saevio', 0.8768550157546997),\n",
       " ('!”', 0.8750863075256348),\n",
       " ('parens', 0.8706927299499512),\n",
       " ('virginitas', 0.8700000047683716),\n",
       " ('casus1', 0.8685871362686157),\n",
       " ('en', 0.8672870993614197),\n",
       " ('ecquis', 0.8627985715866089),\n",
       " ('profugus', 0.8614393472671509)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filius'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which word doesn't go with the others?\n",
    "model.doesnt_match(\"filius pater mater canis\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87677168053217447"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('pater', 'mater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'canis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-633998419771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pater'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'canis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kyle/cltk/venv/lib/python3.4/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \"\"\"\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/cltk/venv/lib/python3.4/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \"\"\"\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'canis'"
     ]
    }
   ],
   "source": [
    "model.similarity('pater', 'canis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01135846,  0.0193827 , -0.04424696,  0.06448502,  0.07657508,\n",
       "       -0.03711487, -0.0270774 ,  0.01487874, -0.02835034, -0.04341644,\n",
       "       -0.00732749,  0.01200995,  0.07838054, -0.03163796, -0.01311052,\n",
       "        0.00202885,  0.00944777,  0.03137747, -0.01638612, -0.01159532,\n",
       "       -0.00729375, -0.02914317, -0.01382305, -0.00218378, -0.00654112,\n",
       "       -0.05540094, -0.02213213, -0.10004523,  0.01012381,  0.02273786,\n",
       "        0.02455524, -0.04728288,  0.00378993,  0.02812943,  0.04177308,\n",
       "       -0.00882489,  0.01114683, -0.0447725 ,  0.11040398, -0.05051815,\n",
       "       -0.01209557,  0.12336719,  0.00746626,  0.05108232, -0.09615205,\n",
       "        0.01124229, -0.01870903,  0.03904261,  0.03580958,  0.01955826,\n",
       "        0.01387766,  0.08324827,  0.03606161, -0.08391311, -0.05632499,\n",
       "        0.06681492, -0.03705744, -0.01570069,  0.0073466 , -0.04375116,\n",
       "       -0.07401293,  0.04874749,  0.06110816, -0.00129882,  0.03043128,\n",
       "       -0.01511536, -0.08096661, -0.02472437,  0.02812227, -0.07483801,\n",
       "       -0.02255343, -0.00451812, -0.00403132, -0.00016473,  0.02864046,\n",
       "        0.01603676, -0.00978272, -0.09573611,  0.02523148, -0.00196346,\n",
       "        0.00158424, -0.05465878,  0.08140562, -0.00770326,  0.02450171,\n",
       "        0.02934963, -0.03374731,  0.06251875, -0.1384853 , -0.09680261,\n",
       "       -0.01806517, -0.0771488 ,  0.01459262, -0.10388903,  0.05164657,\n",
       "       -0.00235097,  0.00048116, -0.04648898,  0.08588129,  0.03512556], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['hasta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
