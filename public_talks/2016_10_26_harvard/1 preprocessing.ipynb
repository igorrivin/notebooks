{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just run these once, following [importing tlg and phi5](http://docs.cltk.org/en/latest/importing_corpora.html#importing-a-corpus), then processing with [tlgu](http://docs.cltk.org/en/latest/greek.html#converting-tlg-texts-with-tlgu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greek (TLG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "from cltk.corpus.utils.formatter import assemble_tlg_author_filepaths\n",
    "from cltk.corpus.utils.formatter import tlg_plaintext_cleanup\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.stop.greek.stops import STOPS_LIST as greek_stops\n",
    "from greek_accentuation.characters import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make working dir\n",
    "user_dir = os.path.expanduser('~/cltk_data/user_data/tlg_lemmatized_no_accents_no_stops')\n",
    "if not os.path.isdir(user_dir):\n",
    "    os.mkdir(user_dir)\n",
    "\n",
    "# rm numbers (eg, αʹβʹ)\n",
    "comp_numbers = re.compile(r'.ʹ+?')\n",
    "\n",
    "# load lemmatizer map into memory\n",
    "# http://docs.cltk.org/en/latest/greek.html#lemmatization\n",
    "lemmatizer = LemmaReplacer('greek')\n",
    "\n",
    "# get filepaths\n",
    "# http://docs.cltk.org/en/latest/greek.html#tlg-indices\n",
    "filepaths = assemble_tlg_author_filepaths()\n",
    "\n",
    "# open each original file, clean, lemmatize, and write into new file\n",
    "for filepath in filepaths:\n",
    "    t0 = time.time()\n",
    "    # open original\n",
    "    with open(filepath) as fo:\n",
    "        text = fo.read()\n",
    "    \n",
    "    # cleanup tlg texts\n",
    "    # http://docs.cltk.org/en/latest/greek.html#text-cleanup\n",
    "    text_cleaned = tlg_plaintext_cleanup(text, rm_punctuation=True, rm_periods=True)\n",
    "    \n",
    "    # rm numbers\n",
    "    text_cleaned = comp_numbers.sub('', text_cleaned)\n",
    "    \n",
    "    # do lemmatization\n",
    "    text_cleaned = text_cleaned.lower()\n",
    "    tokens = lemmatizer.lemmatize(text_cleaned, return_string=False)\n",
    "    \n",
    "    # rm stops\n",
    "    # http://docs.cltk.org/en/latest/greek.html#stopword-filtering\n",
    "    tokens = [w for w in tokens if not w in greek_stops]\n",
    "    \n",
    "    # rm words less than 3 chars\n",
    "    tokens = [w for w in tokens if len(w) > 2]\n",
    "    \n",
    "    #TODO: rm accents\n",
    "    tokens_no_accents = []\n",
    "    for word in tokens:\n",
    "        word_no_accents = []\n",
    "        word = ''.join([base(char) for char in word])\n",
    "        tokens_no_accents.append(word)\n",
    "\n",
    "    #TODO: ''.join()\n",
    "    text_no_accents = ' '.join(tokens_no_accents)\n",
    "\n",
    "    # write file\n",
    "    file_name = os.path.split(filepath)[1]\n",
    "    lemmatized_fp = os.path.join(user_dir, file_name)\n",
    "    with open(lemmatized_fp, 'w') as fo:\n",
    "        fo.write(text_no_accents)\n",
    "#     print('Processing time for {0}: {1} secs.'.format(filepath, time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latin (phi5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.formatter import assemble_phi5_author_filepaths\n",
    "from cltk.corpus.utils.formatter import phi5_plaintext_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make working dir\n",
    "user_dir = os.path.expanduser('~/cltk_data/user_data/phi5_lemmatized')\n",
    "if not os.path.isdir(user_dir):\n",
    "    os.mkdir(user_dir)\n",
    "\n",
    "# load lemmatizer map into memory\n",
    "# http://docs.cltk.org/en/latest/latin.html#lemmatization\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "\n",
    "# get filepaths\n",
    "# http://docs.cltk.org/en/latest/latin.html#phi-indices\n",
    "filepaths = assemble_phi5_author_filepaths()\n",
    "\n",
    "# open each original file, clean, lemmatize, and write into new file\n",
    "for filepath in filepaths:\n",
    "    # open original\n",
    "    with open(filepath) as fo:\n",
    "        text = fo.read()\n",
    "    \n",
    "    # cleanup phi5 texts\n",
    "    # http://docs.cltk.org/en/latest/latin.html#text-cleanup\n",
    "    text_cleaned = phi5_plaintext_cleanup(text, rm_punctuation=True, rm_periods=False)\n",
    "    \n",
    "    # do lemmatization\n",
    "    text_lemmatized = lemmatizer.lemmatize(text_cleaned, return_string=True)\n",
    "    \n",
    "    # write file\n",
    "    file_name = os.path.split(filepath)[1]\n",
    "    lemmatized_fp = os.path.join(user_dir, file_name)\n",
    "    with open(lemmatized_fp, 'w') as fo:\n",
    "        fo.write(text_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
