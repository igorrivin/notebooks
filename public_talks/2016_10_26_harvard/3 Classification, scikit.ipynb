{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_of_author\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_id_author\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_lemmatized_files(corpus_dir):\n",
    "    # return all docs in a dir\n",
    "    user_dir = os.path.expanduser('~/cltk_data/user_data/' + corpus_dir)\n",
    "    files = os.listdir(user_dir)\n",
    "\n",
    "    for file in files:\n",
    "        filepath = os.path.join(user_dir, file)\n",
    "        with open(filepath) as fo:\n",
    "            #TODO rm words less the 3 chars long\n",
    "            yield file[3:-4], fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1823, 5)\n",
      "Time to collect texts: 16.357985019683838\n",
      "Number of texts: 1823\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "map_id_author = get_id_author()\n",
    "\n",
    "df = pandas.DataFrame(columns=['id', 'author' 'text', 'epithet'])\n",
    "\n",
    "for _id, text in stream_lemmatized_files('tlg_lemmatized_no_accents_no_stops'):\n",
    "    author = map_id_author[_id]\n",
    "    epithet = get_epithet_of_author(_id)\n",
    "    df = df.append({'id': _id, 'author': author, 'text': text, 'epithet': epithet}, ignore_index=True)\n",
    "    \n",
    "print(df.shape)\n",
    "print('Time to collect texts: {}'.format(time.time() - t0))\n",
    "print('Number of texts:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_list = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run vectorizer: 138.72214102745056\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2)\n",
    "term_document_matrix = vectorizer.fit_transform(text_list)  # input is a list of strings, 1 per document\n",
    "\n",
    "print('Time to run vectorizer: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put BoW vectors into a new df\n",
    "dataframe_bow = pandas.DataFrame(term_document_matrix.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_list = df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 551779)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_bow['id'] = ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors_list = df['author'].tolist()\n",
    "dataframe_bow['author'] = authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epithets_list = df['epithet'].tolist()\n",
    "dataframe_bow['epithet'] = epithets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Epici/-ae\n",
       "1               Elegiaci\n",
       "2          Historici/-ae\n",
       "3              Biographi\n",
       "4               Bucolici\n",
       "5                Tragici\n",
       "6       Philosophici/-ae\n",
       "7              Sophistae\n",
       "8             Lyrici/-ae\n",
       "9               Oratores\n",
       "10               Tragici\n",
       "11             Epici/-ae\n",
       "12                  None\n",
       "13              Oratores\n",
       "14         Historici/-ae\n",
       "15         Historici/-ae\n",
       "16              Oratores\n",
       "17      Philosophici/-ae\n",
       "18                Comici\n",
       "19             Epici/-ae\n",
       "20             Epici/-ae\n",
       "21             Epici/-ae\n",
       "22             Epici/-ae\n",
       "23              Oratores\n",
       "24              Oratores\n",
       "25              Oratores\n",
       "26              Oratores\n",
       "27              Oratores\n",
       "28                  None\n",
       "29         Historici/-ae\n",
       "              ...       \n",
       "1793                None\n",
       "1794                None\n",
       "1795                None\n",
       "1796                None\n",
       "1797                None\n",
       "1798                None\n",
       "1799                None\n",
       "1800                None\n",
       "1801                None\n",
       "1802           Rhetorici\n",
       "1803                None\n",
       "1804                None\n",
       "1805                None\n",
       "1806                None\n",
       "1807                None\n",
       "1808                None\n",
       "1809        Lexicographi\n",
       "1810                None\n",
       "1811      Paroemiographi\n",
       "1812                None\n",
       "1813      Paroemiographi\n",
       "1814      Paroemiographi\n",
       "1815                None\n",
       "1816              Poetae\n",
       "1817      Paroemiographi\n",
       "1818    Philosophici/-ae\n",
       "1819          Grammatici\n",
       "1820         Alchemistae\n",
       "1821          Grammatici\n",
       "1822           Philologi\n",
       "Name: epithet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow['epithet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489, 551782)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes 334\n",
    "#! remove rows whose epithet = None\n",
    "# note on selecting none in pandas: http://stackoverflow.com/a/24489602\n",
    "dataframe_bow = dataframe_bow[dataframe_bow.epithet.notnull()]\n",
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-18c518d9e95c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#! 2GB, 2 hrs to save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataframe_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/cltk_data/user_data/tlg_bow.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time to save csv: {} mins'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/venv/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1379\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/venv/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/venv/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1574\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/venv/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1600\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;31m# from collections import namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#! 2GB, 2 hrs to save\n",
    "t0 = time.time()\n",
    "dataframe_bow.to_csv(os.path.expanduser('~/cltk_data/user_data/tlg_bow.csv'))\n",
    "td = (time.time() - t0) / 60\n",
    "print('Time to save csv: {} mins'.format(td))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 551781)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ʹʹ</th>\n",
       "      <th>ʹγʹ</th>\n",
       "      <th>ʹδʹ</th>\n",
       "      <th>ʹν</th>\n",
       "      <th>ˈτων</th>\n",
       "      <th>αʹ</th>\n",
       "      <th>αʹβʹ</th>\n",
       "      <th>αʹδʹ</th>\n",
       "      <th>αʹιαʹ</th>\n",
       "      <th>αα</th>\n",
       "      <th>...</th>\n",
       "      <th>ϲωφρονουϲιν</th>\n",
       "      <th>ϲωφρονωϲ</th>\n",
       "      <th>ϲωφρων</th>\n",
       "      <th>ϲωϲ</th>\n",
       "      <th>ϲωϲειε</th>\n",
       "      <th>ϲωϲουϲιν</th>\n",
       "      <th>ϲϛ</th>\n",
       "      <th>ϲϲο</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001</td>\n",
       "      <td>Apollonius Rhodius Epic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0002</td>\n",
       "      <td>Theognis Eleg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0003</td>\n",
       "      <td>Thucydides Hist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0004</td>\n",
       "      <td>Diogenes Laertius Biogr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0005</td>\n",
       "      <td>Theocritus Bucol.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0006</td>\n",
       "      <td>Euripides Trag.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0007</td>\n",
       "      <td>Plutarchus Biogr. et Phil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0008</td>\n",
       "      <td>Athenaeus Soph.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0009</td>\n",
       "      <td>Sappho Lyr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0010</td>\n",
       "      <td>Isocrates Orat.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 551781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ʹʹ  ʹγʹ  ʹδʹ  ʹν  ˈτων   αʹ  αʹβʹ  αʹδʹ  αʹιαʹ  αα  \\\n",
       "0   0    0    0   0     0    0     0     0      0   0   \n",
       "1   0    0    0   0     0    0     0     0      0   0   \n",
       "2   0    0    0   0     0    0     0     0      0   0   \n",
       "3   0    0    0   0     0  593     0     0      0   0   \n",
       "4   0    0    0   0     0    0     0     0      0   0   \n",
       "5   0    0    0   0     0    0     0     0      0   0   \n",
       "6   0    0    0   0     0    0     0     0      0   0   \n",
       "7   0    0    0   0     0   37     0     0      0   0   \n",
       "8   0    0    0   0     0    0     0     0      0   0   \n",
       "9   0    0    0   0     0    1     0     0      0   0   \n",
       "\n",
       "              ...              ϲωφρονουϲιν  ϲωφρονωϲ  ϲωφρων  ϲωϲ  ϲωϲειε  \\\n",
       "0             ...                        0         0       0    0       0   \n",
       "1             ...                        0         0       0    0       0   \n",
       "2             ...                        0         0       0    0       0   \n",
       "3             ...                        0         0       0    0       0   \n",
       "4             ...                        0         0       0    0       0   \n",
       "5             ...                        0         0       0    0       0   \n",
       "6             ...                        0         0       0    0       0   \n",
       "7             ...                        0         0       0    0       0   \n",
       "8             ...                        0         0       0    0       0   \n",
       "9             ...                        0         0       0    0       0   \n",
       "\n",
       "   ϲωϲουϲιν  ϲϛ  ϲϲο    id                      author  \n",
       "0         0   0    0  0001    Apollonius Rhodius Epic.  \n",
       "1         0   0    0  0002              Theognis Eleg.  \n",
       "2         0   0    0  0003            Thucydides Hist.  \n",
       "3         0   0    0  0004    Diogenes Laertius Biogr.  \n",
       "4         0   0    0  0005           Theocritus Bucol.  \n",
       "5         0   0    0  0006             Euripides Trag.  \n",
       "6         0   0    0  0007  Plutarchus Biogr. et Phil.  \n",
       "7         0   0    0  0008             Athenaeus Soph.  \n",
       "8         0   0    0  0009                 Sappho Lyr.  \n",
       "9         0   0    0  0010             Isocrates Orat.  \n",
       "\n",
       "[10 rows x 551781 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyle/venv/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = dataframe_bow['epithet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataframe_bow.drop(['epithet', 'id', 'author'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Take Vectors, \n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    fp_scaler = os.path.expanduser('~/cltk_data/user_data/tlg_bow_scaler.pickle')\n",
    "    joblib.dump(scaler, fp_scaler)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data ...\n",
      "... finished in 0:08:49.920292 secs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, Y_train, Y_test = scale_data(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run decision tree with scikit.\n",
    "    \n",
    "    Experiment with: 'max_depth'\n",
    "    \"\"\"\n",
    "    '''\n",
    "    -This is where we define the models with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "    dec_tree.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(dec_tree, 'models/tree.pickle')  #! ch to cltk_data/user_data\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_tree = dec_tree.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting models ...\n",
      "... finished in 0:58:13.494214 secs.\n",
      "\n",
      "tree_predictions  ['Oratores' 'Scriptores Ecclesiastici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Sophistae' 'Historici/-ae' 'Scriptores Ecclesiastici'\n",
      " 'Historici/-ae' 'Tragici' 'Sophistae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Rhetorici' 'Lyrici/-ae' 'Apologetici' 'Comici'\n",
      " 'Historici/-ae' 'Comici' 'Biographi' 'Historici/-ae' 'Comici' 'Iambici'\n",
      " 'Comici' 'Tragici' 'Philosophici/-ae' 'Tragici' 'Comici'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Sophistae' 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Poetae' 'Philosophici/-ae' 'Grammatici'\n",
      " 'Historici/-ae' 'Poetae' 'Historici/-ae' 'Apologetici' 'Epici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Comici'\n",
      " 'Historici/-ae' 'Grammatici' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Rhetorici' 'Rhetorici'\n",
      " 'Astronomici' 'Scriptores Ecclesiastici' 'Sophistae' 'Comici' 'Theologici'\n",
      " 'Iambici' 'Astrologici' 'Medici' 'Lyrici/-ae' 'Rhetorici' 'Elegiaci'\n",
      " 'Tragici' 'Astronomici' 'Historici/-ae' 'Philosophici/-ae' 'Sophistae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Grammatici'\n",
      " 'Philosophici/-ae' 'Lyrici/-ae' 'Philosophici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Tragici' 'Oratores' 'Theologici' 'Poetae Medici' 'Comici'\n",
      " 'Historici/-ae' 'Comici' 'Tragici' 'Medici' 'Sophistae' 'Grammatici'\n",
      " 'Theologici' 'Philosophici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Theologici' 'Philosophici/-ae' 'Historici/-ae' 'Geographi' 'Musici'\n",
      " 'Philosophici/-ae' 'Tragici' 'Scriptores Ecclesiastici' 'Historici/-ae'\n",
      " 'Geographi' 'Scriptores Ecclesiastici' 'Grammatici' 'Periegetae'\n",
      " 'Geographi' 'Theologici' 'Tragici' 'Tragici' 'Tragici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Philosophici/-ae' 'Sophistae'\n",
      " 'Philosophici/-ae' 'Paradoxographi' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Philosophici/-ae' 'Elegiaci' 'Scriptores Ecclesiastici'\n",
      " 'Sophistae' 'Iambici' 'Sophistae' 'Theologici' 'Historici/-ae' 'Tragici'\n",
      " 'Chronographi' 'Scriptores Ecclesiastici' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Parodii' 'Comici'\n",
      " 'Tragici' 'Historici/-ae' 'Historici/-ae' 'Sophistae' 'Sophistae'\n",
      " 'Grammatici' 'Historici/-ae' 'Philosophici/-ae' 'Apologetici' 'Comici'\n",
      " 'Historici/-ae' 'Geographi' 'Historici/-ae' 'Tragici'\n",
      " 'Scriptores Ecclesiastici' 'Elegiaci' 'Nomographi' 'Comici' 'Sophistae'\n",
      " 'Grammatici' 'Comici' 'Tragici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Tragici' 'Sophistae' 'Astronomici'\n",
      " 'Scriptores Ecclesiastici' 'Biographi' 'Historici/-ae' 'Epigrammatici/-ae'\n",
      " 'Tragici' 'Alchemistae' 'Philosophici/-ae' 'Nomographi'\n",
      " 'Scriptores Ecclesiastici' 'Comici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Comici' 'Comici' 'Historici/-ae' 'Grammatici' 'Comici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Lyrici/-ae' 'Epigrammatici/-ae'\n",
      " 'Comici' 'Comici' 'Philosophici/-ae' 'Lyrici/-ae' 'Historici/-ae' 'Medici'\n",
      " 'Poetae Philosophi' 'Epici/-ae' 'Comici' 'Tragici' 'Philosophici/-ae'\n",
      " 'Geographi' 'Philosophici/-ae' 'Comici' 'Historici/-ae' 'Elegiaci'\n",
      " 'Philosophici/-ae' 'Poetae' 'Comici' 'Biographi' 'Musici'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Tragici' 'Tragici' 'Comici'\n",
      " 'Medici' 'Historici/-ae' 'Tragici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Rhetorici' 'Historici/-ae' 'Sophistae' 'Comici'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Rhetorici' 'Epici/-ae'\n",
      " 'Rhetorici' 'Tragici' 'Philosophici/-ae' 'Medici' 'Philosophici/-ae'\n",
      " 'Tragici' 'Astronomici' 'Paradoxographi' 'Medici' 'Philosophici/-ae'\n",
      " 'Comici' 'Comici' 'Philosophici/-ae' 'Tragici' 'Tragici' 'Historici/-ae'\n",
      " 'Comici' 'Tragici' 'Sophistae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Alchemistae' 'Sophistae' 'Comici' 'Comici' 'Philosophici/-ae' 'Comici'\n",
      " 'Comici' 'Scriptores Ecclesiastici' 'Epici/-ae' 'Comici'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Philosophici/-ae'\n",
      " 'Mechanici' 'Tragici' 'Comici' 'Elegiaci' 'Astrologici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Comici' 'Iambici'\n",
      " 'Grammatici' 'Comici' 'Historici/-ae' 'Mathematici' 'Tragici'\n",
      " 'Historici/-ae' 'Epigrammatici/-ae' 'Parodii' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Scriptores Ecclesiastici'\n",
      " 'Theologici' 'Lyrici/-ae' 'Comici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Mythographi' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Epici/-ae' 'Comici'\n",
      " 'Epigrammatici/-ae' 'Philosophici/-ae' 'Musici' 'Philosophici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Rhetorici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Chronographi' 'Scriptores Ecclesiastici' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Epici/-ae' 'Epici/-ae' 'Epici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Epici/-ae' 'Tragici' 'Elegiaci' 'Tragici' 'Medici' 'Elegiaci'\n",
      " 'Scriptores Ecclesiastici' 'Tragici' 'Tragici' 'Rhetorici' 'Medici'\n",
      " 'Grammatici' 'Historici/-ae' 'Mythographi' 'Tragici' 'Oratores'\n",
      " 'Scriptores Ecclesiastici' 'Historici/-ae' 'Sophistae' 'Theologici'\n",
      " 'Mathematici' 'Theologici' 'Scriptores Ecclesiastici' 'Tragici'\n",
      " 'Philosophici/-ae' 'Elegiaci' 'Elegiaci' 'Tragici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Lyrici/-ae' 'Comici' 'Comici' 'Comici' 'Tragici'\n",
      " 'Philosophici/-ae' 'Tragici']\n",
      "actual_values    9                       Oratores\n",
      "416                   Mimographi\n",
      "1325            Philosophici/-ae\n",
      "556                Historici/-ae\n",
      "1165            Philosophici/-ae\n",
      "396                       Comici\n",
      "1423            Philosophici/-ae\n",
      "1575                Chronographi\n",
      "679             Philosophici/-ae\n",
      "227                      Tragici\n",
      "942             Philosophici/-ae\n",
      "1620               Historici/-ae\n",
      "517             Philosophici/-ae\n",
      "1073                 Apologetici\n",
      "855                   Grammatici\n",
      "481             Philosophici/-ae\n",
      "1392               Historici/-ae\n",
      "1354            Philosophici/-ae\n",
      "108                   Lyrici/-ae\n",
      "572                       Medici\n",
      "1270               Historici/-ae\n",
      "372                       Comici\n",
      "1132                  Lyrici/-ae\n",
      "405                       Comici\n",
      "244                      Tragici\n",
      "929             Philosophici/-ae\n",
      "522                       Medici\n",
      "678             Philosophici/-ae\n",
      "256                  Mathematici\n",
      "806             Philosophici/-ae\n",
      "                  ...           \n",
      "1168               Historici/-ae\n",
      "608                      Tragici\n",
      "799     Scriptores Ecclesiastici\n",
      "630                       Medici\n",
      "84              Philosophici/-ae\n",
      "947                Historici/-ae\n",
      "606             Philosophici/-ae\n",
      "118                     Elegiaci\n",
      "1663               Historici/-ae\n",
      "932                      Tragici\n",
      "1412               Historici/-ae\n",
      "58                     Sophistae\n",
      "1236               Historici/-ae\n",
      "100                    Rhetorici\n",
      "1597                Lexicographi\n",
      "1519    Scriptores Ecclesiastici\n",
      "1339            Philosophici/-ae\n",
      "822             Philosophici/-ae\n",
      "310                       Comici\n",
      "765                Historici/-ae\n",
      "853                      Tragici\n",
      "685             Philosophici/-ae\n",
      "238                      Tragici\n",
      "207                      Tragici\n",
      "1706                   Sophistae\n",
      "375                       Comici\n",
      "8                     Lyrici/-ae\n",
      "1147                     Tragici\n",
      "1614                      Poetae\n",
      "618                   Lyrici/-ae\n",
      "Name: epithet, dtype: object\n",
      "\n",
      "----Tree_report--------------------------------\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             Alchemistae       1.00      0.40      0.57         5\n",
      "             Apologetici       0.00      0.00      0.00         2\n",
      "             Astrologici       0.50      0.50      0.50         2\n",
      "             Astronomici       0.25      0.50      0.33         2\n",
      "              Atticistae       0.00      0.00      0.00         1\n",
      "               Biographi       0.00      0.00      0.00         2\n",
      "                Bucolici       0.00      0.00      0.00         2\n",
      "            Chronographi       0.00      0.00      0.00         1\n",
      "                  Comici       0.30      0.35      0.32        34\n",
      "                Elegiaci       0.00      0.00      0.00         5\n",
      "               Epici/-ae       0.33      0.15      0.21        20\n",
      "       Epigrammatici/-ae       0.00      0.00      0.00         1\n",
      "               Geographi       0.00      0.00      0.00         3\n",
      "                 Gnomici       0.00      0.00      0.00         1\n",
      "              Grammatici       0.40      0.25      0.31        16\n",
      "           Historici/-ae       0.55      0.53      0.54        78\n",
      "             Hymnographi       0.00      0.00      0.00         1\n",
      "                 Iambici       0.00      0.00      0.00         0\n",
      "            Lexicographi       0.00      0.00      0.00         2\n",
      "              Lyrici/-ae       0.00      0.00      0.00        19\n",
      "             Mathematici       0.00      0.00      0.00         1\n",
      "               Mechanici       0.00      0.00      0.00         1\n",
      "                  Medici       0.62      0.36      0.45        14\n",
      "              Mimographi       0.00      0.00      0.00         1\n",
      "                  Musici       0.00      0.00      0.00         2\n",
      "             Mythographi       0.00      0.00      0.00         1\n",
      "              Nomographi       0.00      0.00      0.00         0\n",
      "            Onirocritici       0.00      0.00      0.00         1\n",
      "                Oratores       0.33      0.33      0.33         3\n",
      "          Paradoxographi       0.00      0.00      0.00         0\n",
      "                 Parodii       0.00      0.00      0.00         0\n",
      "          Paroemiographi       0.00      0.00      0.00         2\n",
      "              Periegetae       0.00      0.00      0.00         4\n",
      "               Philologi       0.00      0.00      0.00         2\n",
      "        Philosophici/-ae       0.46      0.43      0.44        70\n",
      "                  Poetae       0.00      0.00      0.00         5\n",
      "        Poetae Didactici       0.00      0.00      0.00         1\n",
      "           Poetae Medici       0.00      0.00      0.00         0\n",
      "       Poetae Philosophi       0.00      0.00      0.00         4\n",
      "               Rhetorici       0.00      0.00      0.00        12\n",
      "Scriptores Ecclesiastici       0.24      0.29      0.26        17\n",
      "      Scriptores Erotici       0.00      0.00      0.00         1\n",
      "               Sophistae       0.06      0.20      0.09         5\n",
      "                 Tactici       0.00      0.00      0.00         2\n",
      "              Theologici       0.11      0.20      0.14         5\n",
      "                 Tragici       0.23      0.45      0.31        22\n",
      "\n",
      "             avg / total       0.34      0.31      0.32       373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyle/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kyle/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run SVC with scikit.\"\"\"\n",
    "    # This is where we define the models with pre-defined parameters\n",
    "    # We can learn these parameters given our data\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    scv = svm.LinearSVC(C=100.)\n",
    "\n",
    "    scv.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    joblib.dump(scv, 'models/svc.pickle')\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = scv.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_svc)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----SVC_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(rf_model)\n",
    "    clf = rf_model.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    joblib.dump(clf, 'models/random_forest.pickle')\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Random forest report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest.\n",
    "    \n",
    "    For plotting see:\n",
    "    http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    ada_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                                        n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(ada_classifier)\n",
    "    clf = ada_classifier.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    joblib.dump(clf, 'models/ada_boost.pickle')\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
