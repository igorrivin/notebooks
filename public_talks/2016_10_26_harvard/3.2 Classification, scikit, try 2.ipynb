{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_of_author\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_id_author\n",
    "import pandas\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_lemmatized_files(corpus_dir):\n",
    "    # return all docs in a dir\n",
    "    user_dir = os.path.expanduser('~/cltk_data/user_data/' + corpus_dir)\n",
    "    files = os.listdir(user_dir)\n",
    "\n",
    "    for file in files:\n",
    "        filepath = os.path.join(user_dir, file)\n",
    "        with open(filepath) as fo:\n",
    "            #TODO rm words less the 3 chars long\n",
    "            yield file[3:-4], fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1823, 5)\n",
      "... finished in 0:00:13.411223\n",
      "Number of texts: 1823\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.datetime.utcnow()\n",
    "\n",
    "map_id_author = get_id_author()\n",
    "\n",
    "df = pandas.DataFrame(columns=['id', 'author' 'text', 'epithet'])\n",
    "\n",
    "for _id, text in stream_lemmatized_files('tlg_lemmatized_no_accents_no_stops'):\n",
    "    author = map_id_author[_id]\n",
    "    epithet = get_epithet_of_author(_id)\n",
    "    df = df.append({'id': _id, 'author': author, 'text': text, 'epithet': epithet}, ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "print('... finished in {}'.format(dt.datetime.utcnow() - t0))\n",
    "print('Number of texts:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_list = df['text'].tolist()\n",
    "\n",
    "# make a list of short texts to drop\n",
    "# For pres, get distributions of words per doc\n",
    "short_text_drop_index = [index if len(text) > 500 else None for index, text in enumerate(text_list) ]  # ~100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished in 0:01:24.611081\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.datetime.utcnow()\n",
    "\n",
    "# TODO: Consdier using generator to CV http://stackoverflow.com/a/21600406\n",
    "\n",
    "# time & size counts, w/ 50 texts:\n",
    "# 0:01:15 & 202M @ ngram_range=(1, 3), min_df=2, max_features=500\n",
    "# 0:00:26 & 80M @ ngram_range=(1, 2), analyzer='word', min_df=2, max_features=5000\n",
    "# 0:00:24 & 81M @ ngram_range=(1, 2), analyzer='word', min_df=2, max_features=50000\n",
    "\n",
    "# time & size counts, w/ 1823 texts:\n",
    "# 0:02:18 & 46MB @ ngram_range=(1, 1), analyzer='word', min_df=2, max_features=500000\n",
    "# 0:2:01 & 47 @ ngram_range=(1, 1), analyzer='word', min_df=2, max_features=1000000\n",
    "\n",
    "# max features in the lemmatized data set: 551428\n",
    "max_features = 100000\n",
    "ngrams = 1\n",
    "vectorizer = CountVectorizer(ngram_range=(1, ngrams), analyzer='word', \n",
    "                             min_df=2, max_features=max_features)\n",
    "term_document_matrix = vectorizer.fit_transform(text_list)  # input is a list of strings, 1 per document\n",
    "\n",
    "# save matrix\n",
    "vector_fp = os.path.expanduser('~/cltk_data/user_data/vectorizer_test_features{0}_ngrams{1}.pickle'.format(max_features, ngrams))\n",
    "joblib.dump(term_document_matrix, vector_fp)\n",
    "\n",
    "print('... finished in {}'.format(dt.datetime.utcnow() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform term matrix into feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put BoW vectors into a new df\n",
    "term_document_matrix = joblib.load(vector_fp)  # scipy.sparse.csr.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 100000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_document_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "term_document_matrix_array = term_document_matrix.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_bow = pandas.DataFrame(term_document_matrix_array, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_list = df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 100000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_bow['id'] = ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors_list = df['author'].tolist()\n",
    "dataframe_bow['author'] = authors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epithets_list = df['epithet'].tolist()\n",
    "dataframe_bow['epithet'] = epithets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Historici/-ae\n",
       "1                        Tragici\n",
       "2                        Tragici\n",
       "3                         Comici\n",
       "4                           None\n",
       "5                           None\n",
       "6                  Historici/-ae\n",
       "7               Philosophici/-ae\n",
       "8                      Sophistae\n",
       "9                     Theologici\n",
       "10                 Historici/-ae\n",
       "11      Scriptores Ecclesiastici\n",
       "12                     Geographi\n",
       "13                    Periegetae\n",
       "14                          None\n",
       "15                    Lyrici/-ae\n",
       "16              Philosophici/-ae\n",
       "17                       Tragici\n",
       "18                          None\n",
       "19                     Geographi\n",
       "20                          None\n",
       "21                        Medici\n",
       "22                     Rhetorici\n",
       "23                 Historici/-ae\n",
       "24                        Medici\n",
       "25                    Lyrici/-ae\n",
       "26                  Onirocritici\n",
       "27                Paradoxographi\n",
       "28      Scriptores Ecclesiastici\n",
       "29                       Tragici\n",
       "                  ...           \n",
       "1793               Historici/-ae\n",
       "1794               Historici/-ae\n",
       "1795               Historici/-ae\n",
       "1796                        None\n",
       "1797               Historici/-ae\n",
       "1798           Epigrammatici/-ae\n",
       "1799                        None\n",
       "1800            Philosophici/-ae\n",
       "1801            Philosophici/-ae\n",
       "1802                    Elegiaci\n",
       "1803           Epigrammatici/-ae\n",
       "1804                     Iambici\n",
       "1805                 Alchemistae\n",
       "1806            Philosophici/-ae\n",
       "1807            Philosophici/-ae\n",
       "1808                      Comici\n",
       "1809                      Comici\n",
       "1810            Philosophici/-ae\n",
       "1811                  Lyrici/-ae\n",
       "1812                   Sophistae\n",
       "1813                   Epici/-ae\n",
       "1814            Philosophici/-ae\n",
       "1815            Philosophici/-ae\n",
       "1816               Historici/-ae\n",
       "1817                 Astronomici\n",
       "1818            Philosophici/-ae\n",
       "1819                  Lyrici/-ae\n",
       "1820               Historici/-ae\n",
       "1821                        None\n",
       "1822                      Comici\n",
       "Name: epithet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For pres, give distribution of epithets, including None\n",
    "dataframe_bow['epithet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489, 100003)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes 334\n",
    "#! remove rows whose epithet = None\n",
    "# note on selecting none in pandas: http://stackoverflow.com/a/24489602\n",
    "dataframe_bow = dataframe_bow[dataframe_bow.epithet.notnull()]\n",
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished in 0:04:17.580780\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.datetime.utcnow()\n",
    "\n",
    "dataframe_bow.to_csv(os.path.expanduser('~/cltk_data/user_data/tlg_bow.csv'))\n",
    "\n",
    "print('... finished in {}'.format(dt.datetime.utcnow() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! TODO Add pandas load from csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489, 100003)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ʹʹ</th>\n",
       "      <th>ʹγʹ</th>\n",
       "      <th>ʹδʹ</th>\n",
       "      <th>αʹ</th>\n",
       "      <th>ααα</th>\n",
       "      <th>ααπτος</th>\n",
       "      <th>ααπτους</th>\n",
       "      <th>ααρων</th>\n",
       "      <th>αασαμην</th>\n",
       "      <th>αασχετον</th>\n",
       "      <th>...</th>\n",
       "      <th>ϲωμα</th>\n",
       "      <th>ϲωματα</th>\n",
       "      <th>ϲωματι</th>\n",
       "      <th>ϲωματοϲ</th>\n",
       "      <th>ϲωματων</th>\n",
       "      <th>ϲωμαϲι</th>\n",
       "      <th>ϲωμαϲιν</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>epithet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1459</td>\n",
       "      <td>Lepidus Hist.</td>\n",
       "      <td>Historici/-ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0825</td>\n",
       "      <td>Melito Trag.</td>\n",
       "      <td>Tragici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0331</td>\n",
       "      <td>[Polyidus] Trag.</td>\n",
       "      <td>Tragici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0417</td>\n",
       "      <td>Archippus Comic.</td>\n",
       "      <td>Comici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2475</td>\n",
       "      <td>Menecrates Hist.</td>\n",
       "      <td>Historici/-ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4075</td>\n",
       "      <td>Marinus Phil.</td>\n",
       "      <td>Philosophici/-ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2127</td>\n",
       "      <td>Troilus Soph.</td>\n",
       "      <td>Sophistae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>Apollinaris Theol.</td>\n",
       "      <td>Theologici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2173</td>\n",
       "      <td>Antileon Hist.</td>\n",
       "      <td>Historici/-ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "      <td>Hermas Scr. Eccl., Pastor Hermae</td>\n",
       "      <td>Scriptores Ecclesiastici</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ʹʹ  ʹγʹ  ʹδʹ  αʹ  ααα  ααπτος  ααπτους  ααρων  αασαμην  αασχετον  \\\n",
       "0    0    0    0   0    0       0        0      0        0         0   \n",
       "1    0    0    0   0    0       0        0      0        0         0   \n",
       "2    0    0    0   0    0       0        0      0        0         0   \n",
       "3    0    0    0   0    0       0        0      0        0         0   \n",
       "6    0    0    0   0    0       0        0      0        0         0   \n",
       "7    0    0    0   0    0       0        0      0        0         0   \n",
       "8    0    0    0   0    0       0        0      0        0         0   \n",
       "9    0    0    0   0    0       0        0      4        0         0   \n",
       "10   0    0    0   0    0       0        0      0        0         0   \n",
       "11   0    0    0   0    0       0        0      0        0         0   \n",
       "\n",
       "              ...             ϲωμα  ϲωματα  ϲωματι  ϲωματοϲ  ϲωματων  ϲωμαϲι  \\\n",
       "0             ...                0       0       0        0        0       0   \n",
       "1             ...                0       0       0        0        0       0   \n",
       "2             ...                0       0       0        0        0       0   \n",
       "3             ...                0       0       0        0        0       0   \n",
       "6             ...                0       0       0        0        0       0   \n",
       "7             ...                0       0       0        0        0       0   \n",
       "8             ...                0       0       0        0        0       0   \n",
       "9             ...                0       0       0        0        0       0   \n",
       "10            ...                0       0       0        0        0       0   \n",
       "11            ...                0       0       0        0        0       0   \n",
       "\n",
       "    ϲωμαϲιν    id                            author                   epithet  \n",
       "0         0  1459                     Lepidus Hist.             Historici/-ae  \n",
       "1         0  0825                      Melito Trag.                   Tragici  \n",
       "2         0  0331                  [Polyidus] Trag.                   Tragici  \n",
       "3         0  0417                  Archippus Comic.                    Comici  \n",
       "6         0  2475                  Menecrates Hist.             Historici/-ae  \n",
       "7         0  4075                     Marinus Phil.          Philosophici/-ae  \n",
       "8         0  2127                     Troilus Soph.                 Sophistae  \n",
       "9         0  2074                Apollinaris Theol.                Theologici  \n",
       "10        0  2173                    Antileon Hist.             Historici/-ae  \n",
       "11        0  1419  Hermas Scr. Eccl., Pastor Hermae  Scriptores Ecclesiastici  \n",
       "\n",
       "[10 rows x 100003 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_bow.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write dataframe_bow to disk, for fast reuse while classifying\n",
    "fp_df = os.path.expanduser('~/cltk_data/user_data/tlg_bow_df.pickle')\n",
    "joblib.dump(dataframe_bow, fp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.load(fp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = dataframe_bow['epithet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataframe_bow.drop(['epithet', 'id', 'author'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Take Vectors, \n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    fp_scaler = os.path.expanduser('~/cltk_data/user_data/tlg_bow_scaler.pickle')\n",
    "    joblib.dump(scaler, fp_scaler)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data ...\n",
      "... finished in 0:00:12.989655 secs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, Y_train, Y_test = scale_data(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run decision tree with scikit.\n",
    "    \n",
    "    Experiment with: 'max_depth'\n",
    "    \"\"\"\n",
    "    '''\n",
    "    -This is where we define the models with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "    dec_tree.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_dt.pickle')\n",
    "    joblib.dump(dec_tree, fp_model_pickle)\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_tree = dec_tree.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting models ...\n",
      "... finished in 0:00:47.223415 secs.\n",
      "\n",
      "tree_predictions  ['Medici' 'Historici/-ae' 'Lyrici/-ae' 'Philosophici/-ae' 'Tragici'\n",
      " 'Comici' 'Tragici' 'Scriptores Ecclesiastici' 'Mimographi' 'Grammatici'\n",
      " 'Lyrici/-ae' 'Musici' 'Comici' 'Historici/-ae' 'Tragici' 'Historici/-ae'\n",
      " 'Theologici' 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Rhetorici' 'Bucolici' 'Historici/-ae' 'Tragici'\n",
      " 'Elegiaci' 'Grammatici' 'Comici' 'Tragici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Medici'\n",
      " 'Comici' 'Philosophici/-ae' 'Historici/-ae' 'Epici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Epici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Epigrammatici/-ae' 'Paradoxographi' 'Elegiaci' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Comici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Scriptores Ecclesiastici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Epici/-ae' 'Tragici' 'Epigrammatici/-ae' 'Comici' 'Chronographi'\n",
      " 'Historici/-ae' 'Paradoxographi' 'Tragici' 'Poetae' 'Comici'\n",
      " 'Scriptores Ecclesiastici' 'Scriptores Ecclesiastici' 'Tragici' 'Comici'\n",
      " 'Tragici' 'Epigrammatici/-ae' 'Epici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Elegiaci' 'Historici/-ae' 'Tragici' 'Astronomici'\n",
      " 'Comici' 'Tragici' 'Lyrici/-ae' 'Tragici' 'Historici/-ae' 'Mathematici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Comici' 'Periegetae' 'Scriptores Erotici'\n",
      " 'Philosophici/-ae' 'Rhetorici' 'Mathematici' 'Paradoxographi' 'Epici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Rhetorici' 'Poetae' 'Comici' 'Gnostici'\n",
      " 'Comici' 'Rhetorici' 'Epigrammatici/-ae' 'Tragici' 'Sophistae'\n",
      " 'Mathematici' 'Epici/-ae' 'Tragici' 'Tragici' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Periegetae' 'Tragici' 'Tragici'\n",
      " 'Mathematici' 'Tragici' 'Lyrici/-ae' 'Paradoxographi' 'Tragici'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Epici/-ae'\n",
      " 'Tragici' 'Rhetorici' 'Historici/-ae' 'Astronomici' 'Lyrici/-ae'\n",
      " 'Mathematici' 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Comici' 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Comici' 'Theologici' 'Grammatici' 'Tragici'\n",
      " 'Historici/-ae' 'Comici' 'Historici/-ae' 'Apologetici'\n",
      " 'Scriptores Erotici' 'Comici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Lyrici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Scriptores Ecclesiastici' 'Grammatici' 'Historici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Paradoxographi' 'Tragici' 'Poetae Philosophi'\n",
      " 'Scriptores Erotici' 'Grammatici' 'Tragici' 'Scriptores Rerum Naturalium'\n",
      " 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Elegiaci' 'Comici' 'Tragici'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Scriptores Ecclesiastici' 'Tragici'\n",
      " 'Theologici' 'Astronomici' 'Rhetorici' 'Historici/-ae' 'Tragici'\n",
      " 'Polyhistorici' 'Historici/-ae' 'Historici/-ae' 'Grammatici' 'Lyrici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Philosophici/-ae' 'Comici' 'Tragici'\n",
      " 'Grammatici' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Comici' 'Tragici' 'Philosophici/-ae' 'Astrologici' 'Philosophici/-ae'\n",
      " 'Comici' 'Comici' 'Elegiaci' 'Historici/-ae' 'Epici/-ae'\n",
      " 'Philosophici/-ae' 'Tragici' 'Historici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Tragici' 'Comici' 'Historici/-ae' 'Geographi'\n",
      " 'Periegetae' 'Mathematici' 'Grammatici' 'Philosophici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Epici/-ae' 'Philosophici/-ae' 'Sophistae'\n",
      " 'Philosophici/-ae' 'Comici' 'Elegiaci' 'Lyrici/-ae' 'Mathematici'\n",
      " 'Scriptores Ecclesiastici' 'Tragici' 'Scriptores Ecclesiastici' 'Comici'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Doxographi'\n",
      " 'Historici/-ae' 'Medici' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Comici' 'Philosophici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Epici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Tragici' 'Philosophici/-ae' 'Philosophici/-ae' 'Mythographi' 'Tragici'\n",
      " 'Tragici' 'Sophistae' 'Philosophici/-ae' 'Poetae' 'Epici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Comici'\n",
      " 'Philosophici/-ae' 'Periegetae' 'Comici' 'Theologici' 'Philologi' 'Medici'\n",
      " 'Comici' 'Comici' 'Tragici' 'Tragici' 'Scriptores Ecclesiastici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Tragici'\n",
      " 'Scriptores Ecclesiastici' 'Poetae' 'Paradoxographi' 'Epici/-ae' 'Tragici'\n",
      " 'Elegiaci' 'Philologi' 'Epici/-ae' 'Philosophici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Astrologici' 'Comici'\n",
      " 'Periegetae' 'Historici/-ae' 'Comici' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Medici' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Mathematici' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Theologici' 'Rhetorici' 'Comici' 'Tragici' 'Comici'\n",
      " 'Rhetorici' 'Philosophici/-ae' 'Paroemiographi' 'Theologici' 'Comici'\n",
      " 'Tragici' 'Elegiaci' 'Tragici' 'Elegiaci' 'Epici/-ae' 'Elegiaci'\n",
      " 'Scriptores Ecclesiastici' 'Sophistae' 'Philosophici/-ae' 'Paroemiographi'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Tragici' 'Medici' 'Comici'\n",
      " 'Grammatici' 'Epigrammatici/-ae' 'Historici/-ae' 'Oratores' 'Tragici'\n",
      " 'Scriptores Ecclesiastici' 'Historici/-ae' 'Tragici' 'Rhetorici'\n",
      " 'Historici/-ae' 'Tragici' 'Comici' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Scriptores Ecclesiastici' 'Scriptores Ecclesiastici']\n",
      "actual_values    11      Scriptores Ecclesiastici\n",
      "440                Historici/-ae\n",
      "1352           Epigrammatici/-ae\n",
      "592                  Apologetici\n",
      "1178                     Tragici\n",
      "413                       Poetae\n",
      "1458                  Lyrici/-ae\n",
      "1621                   Biographi\n",
      "715                    Geographi\n",
      "214                   Grammatici\n",
      "958             Philosophici/-ae\n",
      "1669                      Comici\n",
      "555                      Tragici\n",
      "1092               Historici/-ae\n",
      "874                       Comici\n",
      "513                Historici/-ae\n",
      "1424                  Theologici\n",
      "1381                      Comici\n",
      "99                 Historici/-ae\n",
      "611             Philosophici/-ae\n",
      "1291            Philosophici/-ae\n",
      "377                Historici/-ae\n",
      "1142                   Rhetorici\n",
      "425                       Medici\n",
      "238                Historici/-ae\n",
      "943                       Comici\n",
      "559                       Comici\n",
      "714                   Grammatici\n",
      "249                   Grammatici\n",
      "838                Poetae Medici\n",
      "                  ...           \n",
      "1182                      Comici\n",
      "649                   Lyrici/-ae\n",
      "830                    Epici/-ae\n",
      "672                      Tragici\n",
      "76                 Historici/-ae\n",
      "963                       Poetae\n",
      "647                    Rhetorici\n",
      "109               Paroemiographi\n",
      "1718                      Comici\n",
      "948                   Theologici\n",
      "1447                   Epici/-ae\n",
      "48                    Grammatici\n",
      "1253                   Geographi\n",
      "92                        Comici\n",
      "1641                     Tragici\n",
      "1562            Philosophici/-ae\n",
      "1367          Scriptores Erotici\n",
      "849                Historici/-ae\n",
      "302                   Theologici\n",
      "800                Historici/-ae\n",
      "870                   Lyrici/-ae\n",
      "720                    Biographi\n",
      "231                Historici/-ae\n",
      "193                       Comici\n",
      "1751                      Comici\n",
      "382                   Lyrici/-ae\n",
      "10                 Historici/-ae\n",
      "1157                  Grammatici\n",
      "1660                 Hymnographi\n",
      "659             Philosophici/-ae\n",
      "Name: epithet, dtype: object\n",
      "\n",
      "----Tree_report--------------------------------\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                Alchemistae       0.00      0.00      0.00         5\n",
      "                Apologetici       0.00      0.00      0.00         3\n",
      "                Astrologici       0.00      0.00      0.00         0\n",
      "                Astronomici       0.00      0.00      0.00         7\n",
      "                 Atticistae       0.00      0.00      0.00         1\n",
      "                  Biographi       0.00      0.00      0.00         3\n",
      "                   Bucolici       0.00      0.00      0.00         0\n",
      "               Chronographi       1.00      1.00      1.00         1\n",
      "                     Comici       0.40      0.41      0.41        41\n",
      "                 Doxographi       0.00      0.00      0.00         0\n",
      "                   Elegiaci       0.10      0.17      0.12         6\n",
      "                  Epici/-ae       0.36      0.33      0.34        15\n",
      "          Epigrammatici/-ae       0.20      0.20      0.20         5\n",
      "             Epistolographi       0.00      0.00      0.00         2\n",
      "                  Geographi       0.00      0.00      0.00         5\n",
      "                    Gnomici       0.00      0.00      0.00         1\n",
      "                   Gnostici       0.00      0.00      0.00         1\n",
      "                 Grammatici       0.33      0.16      0.21        19\n",
      "              Historici/-ae       0.67      0.62      0.65        82\n",
      "                Hymnographi       0.00      0.00      0.00         1\n",
      "                    Iambici       0.00      0.00      0.00         1\n",
      "               Lexicographi       0.00      0.00      0.00         1\n",
      "                 Lyrici/-ae       0.00      0.00      0.00        13\n",
      "                Mathematici       0.12      0.33      0.18         3\n",
      "                     Medici       0.33      0.25      0.29         8\n",
      "                 Mimographi       0.00      0.00      0.00         0\n",
      "                     Musici       0.00      0.00      0.00         2\n",
      "                Mythographi       0.00      0.00      0.00         0\n",
      "                   Oratores       0.00      0.00      0.00         1\n",
      "             Paradoxographi       0.00      0.00      0.00         4\n",
      "                    Parodii       0.00      0.00      0.00         1\n",
      "             Paroemiographi       0.50      1.00      0.67         1\n",
      "                 Periegetae       0.20      0.20      0.20         5\n",
      "                  Philologi       0.00      0.00      0.00         1\n",
      "           Philosophici/-ae       0.44      0.51      0.47        53\n",
      "                     Poetae       0.25      0.12      0.17         8\n",
      "              Poetae Medici       0.00      0.00      0.00         1\n",
      "          Poetae Philosophi       0.00      0.00      0.00         0\n",
      "              Polyhistorici       0.00      0.00      0.00         1\n",
      "                  Rhetorici       0.22      0.18      0.20        11\n",
      "   Scriptores Ecclesiastici       0.14      0.30      0.19        10\n",
      "         Scriptores Erotici       0.00      0.00      0.00         1\n",
      "       Scriptores Fabularum       0.00      0.00      0.00         1\n",
      "Scriptores Rerum Naturalium       1.00      1.00      1.00         1\n",
      "                  Sophistae       0.25      0.12      0.17         8\n",
      "                    Tactici       0.00      0.00      0.00         2\n",
      "                 Theologici       0.17      0.11      0.13         9\n",
      "                    Tragici       0.24      0.46      0.32        28\n",
      "\n",
      "                avg / total       0.35      0.36      0.35       373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run SVC with scikit.\"\"\"\n",
    "    # This is where we define the models with pre-defined parameters\n",
    "    # We can learn these parameters given our data\n",
    "    print('Defining and fitting SVC model ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    scv = svm.LinearSVC(C=100.)\n",
    "\n",
    "    scv.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_svc.pickle')\n",
    "    joblib.dump(scv, fp_model_pickle)\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = scv.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----SVC_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting SVC model ...\n"
     ]
    }
   ],
   "source": [
    "run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(rf_model)\n",
    "    clf = rf_model.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    #joblib.dump(clf, 'models/random_forest.pickle')\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_fandom_forest.pickle')\n",
    "    joblib.dump(clf, fp_model_pickle)\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Random forest report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest.\n",
    "    \n",
    "    For plotting see:\n",
    "    http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    ada_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                                        n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(ada_classifier)\n",
    "    clf = ada_classifier.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_ada_boost.pickle')\n",
    "    joblib.dump(clf, fp_model_pickle)\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
