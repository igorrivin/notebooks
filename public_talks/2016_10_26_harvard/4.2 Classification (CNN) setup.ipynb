{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.corpus.utils.formatter import assemble_tlg_author_filepaths\n",
    "from cltk.corpus.utils.formatter import tlg_plaintext_cleanup\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithets\n",
    "from cltk.corpus.greek.tlg.parse_tlg_indices import get_epithet_of_author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make clean plaintext version of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plain_fp = os.path.expanduser('~/cltk_data/greek/text/tlg/plaintext_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished in 0:04:56.467069\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.datetime.utcnow()\n",
    "\n",
    "for file in assemble_tlg_author_filepaths():\n",
    "    with open(file) as fo:\n",
    "        text = fo.read()\n",
    "    text = tlg_plaintext_cleanup(text, rm_punctuation=True, rm_periods=False)\n",
    "    file_name = os.path.split(file)[1]\n",
    "    new_fp = os.path.join(plain_fp, file_name)\n",
    "    with open(new_fp, 'w') as fo:\n",
    "        fo.write(text)\n",
    "\n",
    "print('... finished in {}'.format(dt.datetime.utcnow() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make epithet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plain_fp = os.path.expanduser('~/cltk_data/greek/text/tlg/plaintext_clean')\n",
    "if not os.path.isdir(plain_fp):\n",
    "    print('Process first with `tlg_plaintext_cleanup()`.')\n",
    "    raise\n",
    "\n",
    "cnn_dir = os.path.expanduser('~/cltk_data/user_data/cnn/cnn_frames')\n",
    "try:\n",
    "    os.makedirs(cnn_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_epithet(epithet):\n",
    "    return epithet.replace('/-ae', '').replace(' ', '_').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TokenizeSentence('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished in 0:03:07.561396\n"
     ]
    }
   ],
   "source": [
    "t0 = dt.datetime.utcnow()\n",
    "\n",
    "for file_name in os.listdir(plain_fp):\n",
    "    plain_fp_file = os.path.join(plain_fp, file_name)\n",
    "    _id = file_name[3:-4]\n",
    "    \n",
    "    epithet = get_epithet_of_author(_id)\n",
    "    if epithet is None:\n",
    "        continue\n",
    "    epi_normal = normalize_epithet(epithet)\n",
    "    epithet_file = os.path.join(cnn_dir, epi_normal + '.txt')\n",
    "    \n",
    "    with open(plain_fp_file) as fo:\n",
    "        original_text = fo.read()\n",
    "    sentence_tokens = tokenizer.tokenize_sentences(original_text)[:4]\n",
    "    sentence_tokens = [sent for sent in sentence_tokens if len(sent) > 25]\n",
    "    if len(sentence_tokens) < 3:\n",
    "        continue\n",
    "    sentence_newlines = '\\n'.join(sentence_tokens)\n",
    "    \n",
    "    if not os.path.isfile(epithet_file):\n",
    "        with open(epithet_file, 'w') as fo:\n",
    "            fo.write(sentence_newlines)\n",
    "    else:\n",
    "        with open(epithet_file, 'a') as fo:\n",
    "            fo.write(sentence_newlines)\n",
    "\n",
    "print('... finished in {}'.format(dt.datetime.utcnow() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CNN\n",
    "\n",
    "See modified project from script, tested to classify Historians vs Philosophers\n",
    "\n",
    "Results of `./train.py`:\n",
    "\n",
    "```\n",
    "2016-10-16T19:34:33.239756: step 1593, loss 0.0105471, acc 1\n",
    "2016-10-16T19:34:34.130735: step 1594, loss 0.000387129, acc 1\n",
    "2016-10-16T19:34:35.050536: step 1595, loss 0.0380518, acc 0.984375\n",
    "2016-10-16T19:34:36.104368: step 1596, loss 0.00193451, acc 1\n",
    "2016-10-16T19:34:36.949230: step 1597, loss 0.00110304, acc 1\n",
    "2016-10-16T19:34:38.058944: step 1598, loss 0.0035336, acc 1\n",
    "2016-10-16T19:34:39.078174: step 1599, loss 0.000138309, acc 1\n",
    "2016-10-16T19:34:39.163573: step 1600, loss 1.88347e-05, acc 1\n",
    "\n",
    "Evaluation:\n",
    "2016-10-16T19:34:39.803649: step 1600, loss 0.791714, acc 0.609023\n",
    "\n",
    "Saved model checkpoint to /root/cnn-text-classification-tf/runs/1476645213/checkpoints/model-1600\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
