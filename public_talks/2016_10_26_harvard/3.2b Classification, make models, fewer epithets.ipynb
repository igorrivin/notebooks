{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run this a second time, on the second (`b`) feature table that has removed all epithets with fewer than 27 representative documents. The results are better (overall F1 score for decision tree is `0.44`, random forest is `0.47`; in `a` these were `0.33` and `0.40`, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import clone\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_df = os.path.expanduser('~/cltk_data/user_data/tlg_bow_df.pickle')\n",
    "dataframe_bow = joblib.load(fp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = dataframe_bow['epithet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataframe_bow.drop(['epithet', 'id', 'author'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Take Vectors, \n",
    "    \"\"\"\n",
    "\n",
    "    '''\n",
    "    -PREPOCESSING \n",
    "    -Here, scaled data has zero mean and unit varience\n",
    "    -We save the scaler to later use with testing/prediction data\n",
    "    '''\n",
    "    print('Scaling data ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    fp_scaler = os.path.expanduser('~/cltk_data/user_data/tlg_bow_scaler.pickle')\n",
    "    joblib.dump(scaler, fp_scaler)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data ...\n",
      "... finished in 0:00:02.693181 secs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, Y_train, Y_test = scale_data(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run decision tree with scikit.\n",
    "    \n",
    "    Experiment with: 'max_depth'\n",
    "    \"\"\"\n",
    "    '''\n",
    "    -This is where we define the models with pre-defined parameters\n",
    "    -We can learn these parameters given our data\n",
    "    '''\n",
    "    print('Defining and fitting models ...')\n",
    "    t0 = dt.datetime.utcnow()\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "    dec_tree.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_dt.pickle')\n",
    "    joblib.dump(dec_tree, fp_model_pickle)\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_tree = dec_tree.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction_tree)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Tree_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining and fitting models ...\n",
      "... finished in 0:00:26.187486 secs.\n",
      "\n",
      "tree_predictions  ['Grammatici' 'Scriptores Ecclesiastici' 'Comici' 'Philosophici/-ae'\n",
      " 'Comici' 'Theologici' 'Philosophici/-ae' 'Tragici' 'Lyrici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Tragici' 'Theologici' 'Philosophici/-ae'\n",
      " 'Tragici' 'Scriptores Ecclesiastici' 'Tragici' 'Philosophici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Tragici' 'Comici'\n",
      " 'Historici/-ae' 'Scriptores Ecclesiastici' 'Comici' 'Grammatici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Grammatici'\n",
      " 'Historici/-ae' 'Comici' 'Philosophici/-ae' 'Tragici' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Tragici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Scriptores Ecclesiastici' 'Lyrici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Philosophici/-ae' 'Epici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Rhetorici'\n",
      " 'Philosophici/-ae' 'Comici' 'Comici' 'Philosophici/-ae' 'Tragici' 'Comici'\n",
      " 'Sophistae' 'Philosophici/-ae' 'Tragici' 'Historici/-ae' 'Grammatici'\n",
      " 'Comici' 'Historici/-ae' 'Comici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Sophistae' 'Philosophici/-ae' 'Tragici' 'Scriptores Ecclesiastici'\n",
      " 'Rhetorici' 'Rhetorici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Tragici' 'Lyrici/-ae' 'Tragici' 'Historici/-ae'\n",
      " 'Comici' 'Scriptores Ecclesiastici' 'Alchemistae' 'Historici/-ae'\n",
      " 'Epici/-ae' 'Theologici' 'Historici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Comici' 'Comici' 'Tragici' 'Tragici'\n",
      " 'Medici' 'Medici' 'Comici' 'Tragici' 'Historici/-ae' 'Tragici' 'Sophistae'\n",
      " 'Medici' 'Tragici' 'Philosophici/-ae' 'Philosophici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Rhetorici' 'Tragici' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Rhetorici' 'Historici/-ae' 'Scriptores Ecclesiastici' 'Comici' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Tragici' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Medici' 'Historici/-ae' 'Rhetorici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Elegiaci' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Grammatici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Comici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Tragici' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Medici' 'Historici/-ae' 'Elegiaci' 'Historici/-ae' 'Comici' 'Tragici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Comici' 'Elegiaci' 'Comici' 'Comici'\n",
      " 'Historici/-ae' 'Tragici' 'Tragici' 'Tragici' 'Historici/-ae' 'Grammatici'\n",
      " 'Rhetorici' 'Medici' 'Comici' 'Tragici' 'Historici/-ae' 'Epici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Comici'\n",
      " 'Philosophici/-ae' 'Medici' 'Historici/-ae' 'Philosophici/-ae' 'Comici'\n",
      " 'Tragici' 'Poetae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Tragici' 'Philosophici/-ae' 'Tragici' 'Tragici' 'Historici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Grammatici' 'Tragici' 'Scriptores Ecclesiastici'\n",
      " 'Epici/-ae' 'Historici/-ae' 'Historici/-ae' 'Tragici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Tragici' 'Philosophici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Comici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Philosophici/-ae' 'Scriptores Ecclesiastici'\n",
      " 'Comici' 'Grammatici' 'Lyrici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Sophistae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Tragici' 'Theologici'\n",
      " 'Historici/-ae' 'Tragici' 'Epici/-ae' 'Rhetorici' 'Historici/-ae' 'Comici'\n",
      " 'Tragici' 'Historici/-ae' 'Grammatici' 'Tragici' 'Grammatici'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Lyrici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Comici' 'Comici' 'Comici' 'Historici/-ae' 'Tragici' 'Comici'\n",
      " 'Historici/-ae' 'Tragici' 'Comici' 'Historici/-ae' 'Tragici'\n",
      " 'Philosophici/-ae' 'Medici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Grammatici' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Comici' 'Historici/-ae' 'Tragici' 'Tragici' 'Historici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Tragici' 'Tragici' 'Tragici' 'Comici' 'Historici/-ae'\n",
      " 'Comici' 'Comici' 'Historici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Tragici' 'Philosophici/-ae']\n",
      "actual_values    7               Philosophici/-ae\n",
      "1108    Scriptores Ecclesiastici\n",
      "67                        Comici\n",
      "1233            Philosophici/-ae\n",
      "238                       Comici\n",
      "23      Scriptores Ecclesiastici\n",
      "1228                   Rhetorici\n",
      "514             Philosophici/-ae\n",
      "467                   Lyrici/-ae\n",
      "470                   Theologici\n",
      "1291               Historici/-ae\n",
      "1399                    Elegiaci\n",
      "1163                     Tragici\n",
      "1505                      Comici\n",
      "1370                 Alchemistae\n",
      "657                    Epici/-ae\n",
      "314             Philosophici/-ae\n",
      "1461                      Comici\n",
      "104                      Tragici\n",
      "695                Historici/-ae\n",
      "599             Philosophici/-ae\n",
      "161                       Comici\n",
      "949                   Theologici\n",
      "753                       Comici\n",
      "1460                      Medici\n",
      "267                       Comici\n",
      "1586                      Comici\n",
      "1570                 Alchemistae\n",
      "929                      Tragici\n",
      "811                       Comici\n",
      "                  ...           \n",
      "1199               Historici/-ae\n",
      "503                   Lyrici/-ae\n",
      "871                    Rhetorici\n",
      "673                       Medici\n",
      "100                       Comici\n",
      "593                Historici/-ae\n",
      "1005               Historici/-ae\n",
      "952             Philosophici/-ae\n",
      "1077    Scriptores Ecclesiastici\n",
      "622             Philosophici/-ae\n",
      "1113                      Comici\n",
      "944                    Epici/-ae\n",
      "139                      Tragici\n",
      "1568                    Elegiaci\n",
      "316                Historici/-ae\n",
      "512                       Comici\n",
      "342                Historici/-ae\n",
      "1419               Historici/-ae\n",
      "351                       Comici\n",
      "1400                      Comici\n",
      "688                       Comici\n",
      "159                    Rhetorici\n",
      "1339                      Comici\n",
      "940                       Comici\n",
      "1253               Historici/-ae\n",
      "1338                   Epici/-ae\n",
      "1492                     Tragici\n",
      "981                Historici/-ae\n",
      "1136                     Tragici\n",
      "1094                 Alchemistae\n",
      "Name: epithet, dtype: object\n",
      "\n",
      "----Tree_report--------------------------------\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             Alchemistae       1.00      0.14      0.25         7\n",
      "                  Comici       0.68      0.51      0.58        51\n",
      "                Elegiaci       0.00      0.00      0.00         8\n",
      "               Epici/-ae       0.20      0.05      0.08        19\n",
      "              Grammatici       0.45      0.25      0.32        20\n",
      "           Historici/-ae       0.60      0.75      0.67        84\n",
      "              Lyrici/-ae       0.40      0.17      0.24        12\n",
      "                  Medici       0.25      0.29      0.27         7\n",
      "        Philosophici/-ae       0.47      0.52      0.49        46\n",
      "                  Poetae       0.00      0.00      0.00         7\n",
      "               Rhetorici       0.25      0.17      0.20        12\n",
      "Scriptores Ecclesiastici       0.67      0.62      0.64        13\n",
      "               Sophistae       0.00      0.00      0.00         8\n",
      "              Theologici       0.25      0.20      0.22         5\n",
      "                 Tragici       0.19      0.73      0.30        15\n",
      "\n",
      "             avg / total       0.47      0.46      0.44       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_tree(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    t0 = dt.datetime.utcnow()\n",
    "\n",
    "    n_estimators = 30\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(rf_model)\n",
    "    clf = rf_model.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    #joblib.dump(clf, 'models/random_forest.pickle')\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_fandom_forest.pickle')\n",
    "    joblib.dump(clf, fp_model_pickle)\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----Random forest report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished in 0:00:11.173582 secs.\n",
      "\n",
      "tree_predictions  ['Philosophici/-ae' 'Historici/-ae' 'Comici' 'Philosophici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Tragici'\n",
      " 'Scriptores Ecclesiastici' 'Tragici' 'Tragici' 'Scriptores Ecclesiastici'\n",
      " 'Tragici' 'Philosophici/-ae' 'Tragici' 'Comici' 'Philosophici/-ae'\n",
      " 'Tragici' 'Tragici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Grammatici' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Philosophici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Scriptores Ecclesiastici' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Scriptores Ecclesiastici' 'Epici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Tragici' 'Comici' 'Sophistae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Grammatici' 'Historici/-ae' 'Tragici' 'Comici' 'Tragici'\n",
      " 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Comici' 'Grammatici' 'Philosophici/-ae' 'Tragici'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Philosophici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Epici/-ae' 'Scriptores Ecclesiastici' 'Historici/-ae'\n",
      " 'Tragici' 'Tragici' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Tragici' 'Tragici' 'Rhetorici'\n",
      " 'Grammatici' 'Comici' 'Tragici' 'Historici/-ae' 'Tragici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Historici/-ae' 'Tragici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Comici'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Scriptores Ecclesiastici'\n",
      " 'Historici/-ae' 'Comici' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Scriptores Ecclesiastici' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Tragici' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Comici' 'Philosophici/-ae' 'Comici' 'Tragici'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Tragici' 'Philosophici/-ae' 'Historici/-ae' 'Comici' 'Tragici'\n",
      " 'Historici/-ae' 'Epici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Medici'\n",
      " 'Comici' 'Comici' 'Comici' 'Epici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Historici/-ae' 'Comici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Tragici' 'Comici' 'Poetae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae' 'Comici'\n",
      " 'Philosophici/-ae' 'Tragici' 'Tragici' 'Historici/-ae' 'Tragici' 'Comici'\n",
      " 'Philosophici/-ae' 'Tragici' 'Scriptores Ecclesiastici' 'Epici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Tragici' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Tragici' 'Tragici' 'Historici/-ae' 'Historici/-ae' 'Comici'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Scriptores Ecclesiastici'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Comici' 'Philosophici/-ae' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Historici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Tragici' 'Historici/-ae' 'Rhetorici' 'Historici/-ae'\n",
      " 'Comici' 'Tragici' 'Historici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Philosophici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Historici/-ae' 'Historici/-ae' 'Historici/-ae'\n",
      " 'Philosophici/-ae' 'Comici' 'Philosophici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Tragici' 'Comici' 'Historici/-ae' 'Tragici' 'Comici' 'Historici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Medici' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Philosophici/-ae' 'Historici/-ae' 'Philosophici/-ae'\n",
      " 'Comici' 'Historici/-ae' 'Philosophici/-ae' 'Lyrici/-ae' 'Historici/-ae'\n",
      " 'Tragici' 'Historici/-ae' 'Tragici' 'Tragici' 'Tragici' 'Comici'\n",
      " 'Historici/-ae' 'Comici' 'Comici' 'Historici/-ae' 'Comici' 'Historici/-ae'\n",
      " 'Historici/-ae' 'Tragici' 'Philosophici/-ae']\n",
      "actual_values    7               Philosophici/-ae\n",
      "1108    Scriptores Ecclesiastici\n",
      "67                        Comici\n",
      "1233            Philosophici/-ae\n",
      "238                       Comici\n",
      "23      Scriptores Ecclesiastici\n",
      "1228                   Rhetorici\n",
      "514             Philosophici/-ae\n",
      "467                   Lyrici/-ae\n",
      "470                   Theologici\n",
      "1291               Historici/-ae\n",
      "1399                    Elegiaci\n",
      "1163                     Tragici\n",
      "1505                      Comici\n",
      "1370                 Alchemistae\n",
      "657                    Epici/-ae\n",
      "314             Philosophici/-ae\n",
      "1461                      Comici\n",
      "104                      Tragici\n",
      "695                Historici/-ae\n",
      "599             Philosophici/-ae\n",
      "161                       Comici\n",
      "949                   Theologici\n",
      "753                       Comici\n",
      "1460                      Medici\n",
      "267                       Comici\n",
      "1586                      Comici\n",
      "1570                 Alchemistae\n",
      "929                      Tragici\n",
      "811                       Comici\n",
      "                  ...           \n",
      "1199               Historici/-ae\n",
      "503                   Lyrici/-ae\n",
      "871                    Rhetorici\n",
      "673                       Medici\n",
      "100                       Comici\n",
      "593                Historici/-ae\n",
      "1005               Historici/-ae\n",
      "952             Philosophici/-ae\n",
      "1077    Scriptores Ecclesiastici\n",
      "622             Philosophici/-ae\n",
      "1113                      Comici\n",
      "944                    Epici/-ae\n",
      "139                      Tragici\n",
      "1568                    Elegiaci\n",
      "316                Historici/-ae\n",
      "512                       Comici\n",
      "342                Historici/-ae\n",
      "1419               Historici/-ae\n",
      "351                       Comici\n",
      "1400                      Comici\n",
      "688                       Comici\n",
      "159                    Rhetorici\n",
      "1339                      Comici\n",
      "940                       Comici\n",
      "1253               Historici/-ae\n",
      "1338                   Epici/-ae\n",
      "1492                     Tragici\n",
      "981                Historici/-ae\n",
      "1136                     Tragici\n",
      "1094                 Alchemistae\n",
      "Name: epithet, dtype: object\n",
      "\n",
      "----Random forest report--------------------------------\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             Alchemistae       0.00      0.00      0.00         7\n",
      "                  Comici       0.82      0.63      0.71        51\n",
      "                Elegiaci       0.00      0.00      0.00         8\n",
      "               Epici/-ae       0.40      0.11      0.17        19\n",
      "              Grammatici       0.75      0.15      0.25        20\n",
      "           Historici/-ae       0.59      0.89      0.71        84\n",
      "              Lyrici/-ae       0.00      0.00      0.00        12\n",
      "                  Medici       1.00      0.29      0.44         7\n",
      "        Philosophici/-ae       0.47      0.74      0.58        46\n",
      "                  Poetae       0.00      0.00      0.00         7\n",
      "               Rhetorici       1.00      0.17      0.29        12\n",
      "Scriptores Ecclesiastici       0.50      0.38      0.43        13\n",
      "               Sophistae       0.00      0.00      0.00         8\n",
      "              Theologici       0.00      0.00      0.00         5\n",
      "                 Tragici       0.22      0.73      0.34        15\n",
      "\n",
      "             avg / total       0.52      0.53      0.47       314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_random_forest(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Run SVC with scikit.\"\"\"\n",
    "    # This is where we define the models with pre-defined parameters\n",
    "    # We can learn these parameters given our data\n",
    "    print('Defining and fitting SVC model ...')\n",
    "    t0 = dt.datetime.utcnow()   \n",
    "    scv = svm.LinearSVC(C=100.)\n",
    "\n",
    "    scv.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_svc.pickle')\n",
    "    joblib.dump(scv, fp_model_pickle)\n",
    "\n",
    "    print('... finished in {} secs.'.format(dt.datetime.utcnow() - t0))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    Y_prediction_svc = scv.predict(X_test_scaled)\n",
    "    print('svc_predictions ', Y_prediction_svc)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('----SVC_report--------------------------------')\n",
    "    print(classification_report(expected, Y_prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_svc(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test):\n",
    "    \"\"\"Scikit random forest.\n",
    "    \n",
    "    For plotting see:\n",
    "    http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html\n",
    "    \n",
    "    Experiment with 'n_estimators'\n",
    "    \"\"\"\n",
    "    \n",
    "    n_estimators = 30\n",
    "    ada_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                                        n_estimators=n_estimators)\n",
    "\n",
    "    # Train\n",
    "    clf = clone(ada_classifier)\n",
    "    clf = ada_classifier.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    fp_model_pickle = os.path.expanduser('~/cltk_data/user_data/tlg_bow_ada_boost.pickle')\n",
    "    joblib.dump(clf, fp_model_pickle)\n",
    "    \n",
    "    scores = clf.score(X_train_scaled, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_prediction = clf.predict(X_test_scaled)\n",
    "    print('tree_predictions ', Y_prediction)\n",
    "\n",
    "    expected = Y_test\n",
    "    print('actual_values   ', expected)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(classification_report(expected, Y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_ada_boost(X_train_scaled, X_test_scaled, Y_train, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
