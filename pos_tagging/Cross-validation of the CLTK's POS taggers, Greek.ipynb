{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cross-validates the CLTK's part-of-speech taggers. The final results are found at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import TaggedCorpusReader\n",
    "from nltk.tag import AffixTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import tnt\n",
    "from nltk.tag import TrigramTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from statistics import mean\n",
    "from statistics import stdev\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_training_set_rel = '~/greek_treebank_perseus/greek_training_set.pos'\n",
    "full_training_set = os.path.expanduser(full_training_set_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop #0\n",
      "Unigram: 0.8170218852810757\n",
      "Bigram: 0.2537548276355314\n",
      "Trigram: 0.1938492347303676\n",
      "1, 2, 3-gram backoff: 0.820569303390073\n",
      "TnT: 0.8299241882420254\n",
      "Runtime: 631.0014109611511\n",
      "\n",
      "Loop #1\n",
      "Unigram: 0.8126170079990923\n",
      "Bigram: 0.25401372893856017\n",
      "Trigram: 0.19186475293583707\n",
      "1, 2, 3-gram backoff: 0.8170987689340217\n",
      "TnT: 0.8242752595450161\n",
      "Runtime: 592.7357261180878\n",
      "\n",
      "Loop #2\n",
      "Unigram: 0.8172981269363044\n",
      "Bigram: 0.2615183469289145\n",
      "Trigram: 0.20057982548389847\n",
      "1, 2, 3-gram backoff: 0.8219310462439247\n",
      "TnT: 0.8330727908364836\n",
      "Runtime: 705.8858499526978\n",
      "\n",
      "Loop #3\n",
      "Unigram: 0.8176651870281886\n",
      "Bigram: 0.2541773869772965\n",
      "Trigram: 0.19336141819107128\n",
      "1, 2, 3-gram backoff: 0.8211710820209788\n",
      "TnT: 0.8313494868387571\n",
      "Runtime: 711.4081230163574\n",
      "\n",
      "Loop #4\n",
      "Unigram: 0.8136574721647177\n",
      "Bigram: 0.2548816650814077\n",
      "Trigram: 0.19680523694958876\n",
      "1, 2, 3-gram backoff: 0.8151121803838192\n",
      "TnT: 0.8273932747720024\n",
      "Runtime: 702.5740129947662\n",
      "\n",
      "Loop #5\n",
      "Unigram: 0.812089356110381\n",
      "Bigram: 0.2519710906701708\n",
      "Trigram: 0.18851292159439334\n",
      "1, 2, 3-gram backoff: 0.8137593079281646\n",
      "TnT: 0.8251752080595708\n",
      "Runtime: 545.2309489250183\n",
      "\n",
      "Loop #6\n",
      "Unigram: 0.8137136093340472\n",
      "Bigram: 0.25987092410450074\n",
      "Trigram: 0.2011949384212158\n",
      "1, 2, 3-gram backoff: 0.8169264154665614\n",
      "TnT: 0.827494856691937\n",
      "Runtime: 540.8957121372223\n",
      "\n",
      "Loop #7\n",
      "Unigram: 0.8149580548841178\n",
      "Bigram: 0.2555950518981942\n",
      "Trigram: 0.1952509597611261\n",
      "1, 2, 3-gram backoff: 0.8230058296601734\n",
      "TnT: 0.8286933030001422\n",
      "Runtime: 513.0061490535736\n",
      "\n",
      "Loop #8\n",
      "Unigram: 0.8165790287658522\n",
      "Bigram: 0.252228439670444\n",
      "Trigram: 0.19494980738407897\n",
      "1, 2, 3-gram backoff: 0.8170570536793859\n",
      "TnT: 0.8296544161066277\n",
      "Runtime: 492.7715480327606\n",
      "\n",
      "Loop #9\n",
      "Unigram: 0.8166695006518165\n",
      "Bigram: 0.2617185285949102\n",
      "Trigram: 0.201241285495664\n",
      "1, 2, 3-gram backoff: 0.8200986226832171\n",
      "TnT: 0.829790851895936\n",
      "Runtime: 556.2160589694977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This section's code is good, but it times out in IPython.\n",
    "# Consider using it in separate scripts.\n",
    "unigram_accuracies = []\n",
    "bigram_accuracies = []\n",
    "trigram_accuracies = []\n",
    "backoff_accuracies = []\n",
    "tnt_accuracies = []\n",
    "\n",
    "with open(full_training_set) as f:\n",
    "    training_set_string = f.read()\n",
    "\n",
    "pos_set = training_set_string.split('\\n\\n')  # mk into a list\n",
    "\n",
    "sentence_count = len(pos_set)  # 24825 \n",
    "tenth = math.ceil(int(sentence_count) / int(10))\n",
    "\n",
    "random.shuffle(pos_set)\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\n",
    "    http://stackoverflow.com/a/312464\n",
    "    \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "# a list of 10 lists\n",
    "ten_parts = list(chunks(pos_set, tenth))  # a list of 10 lists with ~2483 sentences each\n",
    "\n",
    "#for counter in list(range(10)):\n",
    "for counter, part in list(enumerate(ten_parts)):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # map test list to part of given loop\n",
    "    test_set = ten_parts[counter]  # or: test_set = part\n",
    "    \n",
    "    # filter out this loop's test index\n",
    "    training_set_lists = [x for x in ten_parts if x is not ten_parts[counter]]\n",
    "    \n",
    "    # next concatenate the list together into 1 file ( http://stackoverflow.com/a/952952 )\n",
    "    training_set = [item for sublist in training_set_lists for item in sublist]\n",
    "        \n",
    "    # save shuffled tests to file\n",
    "    # there might be a way of getting \n",
    "    local_dir_rel = '~/cltk_data/user_data'\n",
    "    local_dir = os.path.expanduser(local_dir_rel)\n",
    "    if not os.path.isdir(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    test_path = os.path.join(local_dir, 'test_greek.pos')\n",
    "    with open(test_path, 'w') as f:\n",
    "        f.write('\\n\\n'.join(test_set))\n",
    "\n",
    "    train_path = os.path.join(local_dir, 'train_greek.pos')\n",
    "    with open(train_path, 'w') as f:\n",
    "        f.write('\\n\\n'.join(training_set))\n",
    "\n",
    "    # read POS corpora\n",
    "    train_reader = TaggedCorpusReader(local_dir, 'train_greek.pos')\n",
    "    train_sents = train_reader.tagged_sents()\n",
    "\n",
    "    test_reader = TaggedCorpusReader(local_dir, 'test_greek.pos')\n",
    "    test_sents = test_reader.tagged_sents()\n",
    "    \n",
    "    print('Loop #' + str(counter))\n",
    "    # make unigram tagger\n",
    "    unigram_tagger = UnigramTagger(train_sents)\n",
    "    # evaluate unigram tagger\n",
    "    unigram_accuracy = None\n",
    "    unigram_accuracy = unigram_tagger.evaluate(test_sents)\n",
    "    unigram_accuracies.append(unigram_accuracy)\n",
    "    print('Unigram:', unigram_accuracy)\n",
    "    \n",
    "    # make bigram tagger\n",
    "    bigram_tagger = BigramTagger(train_sents)\n",
    "    # evaluate bigram tagger\n",
    "    bigram_accuracy = None\n",
    "    bigram_accuracy = bigram_tagger.evaluate(test_sents)\n",
    "    bigram_accuracies.append(bigram_accuracy)\n",
    "    print('Bigram:', bigram_accuracy)\n",
    "    \n",
    "    # make trigram tagger\n",
    "    trigram_tagger = TrigramTagger(train_sents)\n",
    "    # evaluate trigram tagger\n",
    "    trigram_accuracy = None\n",
    "    trigram_accuracy = trigram_tagger.evaluate(test_sents)\n",
    "    trigram_accuracies.append(trigram_accuracy)\n",
    "    print('Trigram:', trigram_accuracy)\n",
    "    \n",
    "    # make 1, 2, 3-gram backoff tagger\n",
    "    tagger1 = UnigramTagger(train_sents)\n",
    "    tagger2 = BigramTagger(train_sents, backoff=tagger1)\n",
    "    tagger3 = TrigramTagger(train_sents, backoff=tagger2)\n",
    "    # evaluate trigram tagger\n",
    "    backoff_accuracy = None\n",
    "    backoff_accuracy = tagger3.evaluate(test_sents)\n",
    "    backoff_accuracies.append(backoff_accuracy)\n",
    "    print('1, 2, 3-gram backoff:', backoff_accuracy)\n",
    "    \n",
    "    # make tnt tagger\n",
    "    tnt_tagger = tnt.TnT(N=100)  # N=1000 is default but but won't finish with Greek\n",
    "    tnt_tagger.train(train_sents)\n",
    "    # evaulate tnt tagger\n",
    "    tnt_accuracy = None\n",
    "    tnt_accuracy = tnt_tagger.evaluate(test_sents)\n",
    "    tnt_accuracies.append(tnt_accuracy)\n",
    "    print('TnT:', tnt_accuracy)\n",
    "    \n",
    "    print('Runtime:', time.time() - start)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_accuracies_list = []\n",
    "mean_accuracy_unigram = mean(unigram_accuracies)\n",
    "standard_deviation_unigram = stdev(unigram_accuracies)\n",
    "uni = {'unigram': {'mean': mean_accuracy_unigram, 'sd': standard_deviation_unigram}}\n",
    "final_accuracies_list.append(uni)\n",
    "\n",
    "mean_accuracy_bigram = mean(bigram_accuracies)\n",
    "standard_deviation_bigram = stdev(bigram_accuracies)\n",
    "bi = {'bigram': {'mean': mean_accuracy_bigram, 'sd': standard_deviation_bigram}}\n",
    "final_accuracies_list.append(bi)\n",
    "\n",
    "mean_accuracy_trigram = mean(trigram_accuracies)\n",
    "standard_deviation_trigram = stdev(trigram_accuracies)\n",
    "tri = {'trigram': {'mean': mean_accuracy_trigram, 'sd': standard_deviation_trigram}}\n",
    "final_accuracies_list.append(tri)\n",
    "\n",
    "mean_accuracy_backoff = mean(backoff_accuracies)\n",
    "standard_deviation_backoff = stdev(backoff_accuracies)\n",
    "back = {'1, 2, 3-gram backoff': {'mean': mean_accuracy_backoff, 'sd': standard_deviation_backoff}}\n",
    "final_accuracies_list.append(back)\n",
    "\n",
    "mean_accuracy_tnt = mean(tnt_accuracies)\n",
    "standard_deviation_tnt = stdev(tnt_accuracies)\n",
    "tnt = {'tnt': {'mean': mean_accuracy_tnt, 'sd': standard_deviation_tnt}}\n",
    "final_accuracies_list.append(tnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1, 2, 3-gram backoff</th>\n",
       "      <th>bigram</th>\n",
       "      <th>tnt</th>\n",
       "      <th>trigram</th>\n",
       "      <th>unigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td> 0.818673</td>\n",
       "      <td> 0.255973</td>\n",
       "      <td> 0.828682</td>\n",
       "      <td> 0.195761</td>\n",
       "      <td> 0.815227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td> 0.003095</td>\n",
       "      <td> 0.003686</td>\n",
       "      <td> 0.002685</td>\n",
       "      <td> 0.004242</td>\n",
       "      <td> 0.002078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1, 2, 3-gram backoff    bigram       tnt   trigram   unigram\n",
       "mean              0.818673  0.255973  0.828682  0.195761  0.815227\n",
       "sd                0.003095  0.003686  0.002685  0.004242  0.002078"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict = {}\n",
    "for x in final_accuracies_list:\n",
    "    final_dict.update(x)\n",
    "\n",
    "df = pd.DataFrame(final_dict)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
