{
 "metadata": {
  "name": "",
  "signature": "sha256:0c55a3d15100f877513da10264e20552d10777b66b58fdd60c000e7270f9f51b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cltk.stem.lemma import LemmaReplacer\n",
      "from cltk.stem.latin.j_v import JVReplacer\n",
      "from cltk.stop.latin.stops import STOPS_LIST\n",
      "from collections import Counter\n",
      "from nltk.tokenize.punkt import PunktWordTokenizer\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "import numpy\n",
      "import os\n",
      "import re\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lemmatizing is optional and probably not useful \n",
      "# in this tf-idf case\n",
      "#lemmatizer = LemmaReplacer('latin')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_phi5_index():\n",
      "    \"\"\"Returns dict of {file: author_name}\n",
      "    Should return 362 files.\n",
      "    \"\"\"\n",
      "    index_path_rel = '~/cltk_data/originals/phi5/AUTHTAB.DIR'\n",
      "    index_path = os.path.expanduser(index_path_rel)\n",
      "    with open(index_path, 'rb') as f:\n",
      "        r = f.read()\n",
      "        index_all = r.decode('latin-1').split('\\xff')[1:-21]\n",
      "        index = [x for x in index_all if x]\n",
      "        file_author = {}\n",
      "        for x in index:\n",
      "            # file name\n",
      "            pattern_file = re.compile('LAT[\\d].{4}')\n",
      "            m = pattern_file.match(x)\n",
      "            file_name = m.group()[:-1] + '.TXT'\n",
      "\n",
      "            # author name\n",
      "            author_name = pattern_file.split(x)[-1]\n",
      "            pattern_author = re.compile('&1|&\u0083l|l$|&|1$|\\x83')\n",
      "            author_name = pattern_author.sub('', author_name)\n",
      "            pattern_comma = re.compile('\\x80')\n",
      "            author_name = pattern_comma.sub(', ', author_name)\n",
      "            file_author[file_name] = author_name\n",
      "\n",
      "    return file_author"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phi5_index = build_phi5_index()\n",
      "\n",
      "plaintext_dir_rel = '~/cltk_data/latin/text/phi5/plaintext/'\n",
      "plaintext_dir = os.path.expanduser(plaintext_dir_rel)\n",
      "phi5_files = [os.path.join(plaintext_dir, x) for x in phi5_index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cltk.corpus.utils.formatter import cleanup_tlg_txt, remove_non_ascii\n",
      "\n",
      "def join_hyphens(str_text):\n",
      "    return str_text.replace('-\\n', '')\n",
      "\n",
      "def join_lines(str_text):\n",
      "    return str_text.replace('\\n', ' ')\n",
      "\n",
      "def rm_titles(text):\n",
      "    pattern = re.compile('\\{.+?\\}')\n",
      "    return pattern.sub('', text)\n",
      "\n",
      "def rm_pointed_brackets(str_text):\n",
      "    str_text = str_text.replace('<', '')\n",
      "    return str_text.replace('>', '')\n",
      "\n",
      "def phi5_plaintext_cleanup(str_text):\n",
      "    str_text = join_hyphens(str_text)\n",
      "    str_text = join_lines(str_text)\n",
      "    str_text = rm_titles(str_text)\n",
      "    return rm_pointed_brackets(str_text)\n",
      "\n",
      "def clean_read(file_path):\n",
      "    with open(file_path) as f:\n",
      "        r = f.read()\n",
      "        return phi5_plaintext_cleanup(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [clean_read(f) for f in phi5_files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n",
      "tfidf = TfidfVectorizer().fit_transform(documents)\n",
      "pairwise_similarity = (tfidf * tfidf.T).A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print arrays, 362 lines x 362 scores each\n",
      "ps_file_rel = '~/cltk_data/user_data/phi5_tfidf_pairwise_sims.txt'\n",
      "ps_rel = os.path.expanduser(ps_file_rel)\n",
      "numpy.savetxt(ps_rel,\n",
      "              pairwise_similarity,\n",
      "              fmt='%1.8f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now match line numbers with their order in phi5_index\n",
      "# make list of authors indexed by their order\n",
      "counter_author = {}\n",
      "for x, y in enumerate(phi5_index):\n",
      "    counter_author[x] = phi5_index[y]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a dict of author name + list of scores\n",
      "author_scores = {}\n",
      "import csv\n",
      "with open(ps_rel, newline='') as csvfile:\n",
      "    array_reader = csv.reader(csvfile, delimiter=' ')\n",
      "    for line, numbers in enumerate(array_reader):\n",
      "        row_author_name = counter_author[line]\n",
      "        author_scores[row_author_name] = numbers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_pairwise_comps = {}\n",
      "for name, scores in author_scores.items():\n",
      "    for number, score in enumerate(scores):\n",
      "        if number in counter_author.keys():\n",
      "            author_name_score = counter_author[number]\n",
      "            author_comparison_pair = name + ' v. ' + author_name_score\n",
      "            final_pairwise_comps[author_comparison_pair] = score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "\n",
      "ps_file_final_rel = '~/cltk_data/user_data/phi5_tfidf_pairwise_sims_final.txt'\n",
      "ps_final = os.path.expanduser(ps_file_final_rel)\n",
      "with open(ps_final, 'w') as out:\n",
      "    pprint(final_pairwise_comps, stream=out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}