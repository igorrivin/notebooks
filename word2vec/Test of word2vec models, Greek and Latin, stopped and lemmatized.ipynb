{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a qualitative test of results returned by word2vec models generated by means of the CLTK and gensim's implementation of the algorithm. There are four models for Latin and Greek each, with the following parameters:\n",
    "\n",
    "* lemmatized and stopwords removed\n",
    "* lemmatized \n",
    "* stopwords removed\n",
    "* plaintext (ie, not lemmatized nor stopwords removed)\n",
    "\n",
    "All the models were build with `Word2Vec()` arguments `size=100`, `window=5`, and `min_count=5`. The code made to generate these is in notebook </word2vec_build_model_phi5_tlg_test>. It was run on a remote server [with this setup code](https://github.com/kylepjohnson/cltk_remote_setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_paths = {'lemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_latin_lemmatizer_stops.model',\n",
    "                'lemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_latin_lemmatizer.model',\n",
    "                'unlemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_latin_stops.model',\n",
    "                'unlemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_latin.model'}\n",
    "\n",
    "save_dir = '~/cltk_data/user_data/word2vec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sims(model_name, word_1, word_2=None):\n",
    "    word = word_1\n",
    "    if word_2 and model_name in ['lemmatized_no_stops', 'lemmatized_yes_stops']:\n",
    "        word = word_2\n",
    "    return word_1, model.most_similar(word)\n",
    "\n",
    "def print_sims(word_all_models_list):\n",
    "    for headword, sims in word_all_models_list.items():\n",
    "        print(colored(headword, 'red'))\n",
    "        for sims_pair in sims:\n",
    "            print(colored(sims_pair[0], 'blue'))\n",
    "            for sim in sims_pair[1]:\n",
    "                print(sim)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_all_models_list = defaultdict(list)\n",
    "for model_name, model_path in models_paths.items():\n",
    "\n",
    "    # setup paths\n",
    "    model_path = os.path.expanduser(model_path)\n",
    "    save_dir = os.path.expanduser(save_dir)\n",
    "    save_file = os.path.join(save_dir, model_name)\n",
    "\n",
    "    model = Word2Vec.load(model_path)\n",
    "\n",
    "    words = ['amicitia', ('carus', 'carus1'), 'dignitas', 'amo', 'amor', ('industria', 'industria1'), \n",
    "             'facio', 'laus', 'scribo', 'cano', 'pudor']\n",
    "    for word in words:\n",
    "        if type(word) is str:\n",
    "            headword, sims = get_sims(model_name, word)\n",
    "        elif type(word) is tuple:\n",
    "            headword, sims = get_sims(model_name, word[0], word[1])\n",
    "        word_all_models_list[headword].append((model_name, sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mamicitia\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('commendatione', 0.743280827999115)\n",
      "('improbitate', 0.7342466115951538)\n",
      "('honorificentissime', 0.7253440022468567)\n",
      "('beneuolentia', 0.7121111154556274)\n",
      "('dignitate', 0.7069240808486938)\n",
      "('liberalitas', 0.7062676548957825)\n",
      "('dignitas', 0.7037380337715149)\n",
      "('familiaritate', 0.7029399275779724)\n",
      "('sesti', 0.6999698877334595)\n",
      "('accurata', 0.6967668533325195)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('beneuolentia', 0.7057880759239197)\n",
      "('dignitate', 0.69084632396698)\n",
      "('eloquentia', 0.6800093650817871)\n",
      "('disciplina', 0.6777817606925964)\n",
      "('errato', 0.6772070527076721)\n",
      "('societate', 0.6766867637634277)\n",
      "('fide', 0.6733757257461548)\n",
      "('temperantia', 0.673005998134613)\n",
      "('calamitate', 0.6682467460632324)\n",
      "('prudentia', 0.6669106483459473)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('liberalitas', 0.6977777481079102)\n",
      "('beneficium', 0.6852203011512756)\n",
      "('necessitudo', 0.6782779693603516)\n",
      "('humanitas', 0.6631476283073425)\n",
      "('obseruantia', 0.6609437465667725)\n",
      "('societas', 0.6592288017272949)\n",
      "('familiaritas', 0.657794713973999)\n",
      "('beneuolens', 0.6521384716033936)\n",
      "('beneuolentia', 0.6520812511444092)\n",
      "('erga', 0.6485866904258728)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('societas', 0.7176007628440857)\n",
      "('liberalitas', 0.694193959236145)\n",
      "('beneuolentia', 0.6752265095710754)\n",
      "('fido', 0.6644117832183838)\n",
      "('beneuolens', 0.6507399082183838)\n",
      "('familiaritas', 0.6430079340934753)\n",
      "('humanitas', 0.6386340856552124)\n",
      "('fides1', 0.6246727705001831)\n",
      "('dignitas', 0.616410493850708)\n",
      "('necessitudo', 0.6114685535430908)\n",
      "\n",
      "\u001b[31mamor\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('pudor', 0.6753295063972473)\n",
      "('pudoris', 0.6614177227020264)\n",
      "('tantus', 0.6592569947242737)\n",
      "('dolor', 0.6481508612632751)\n",
      "('pietas', 0.622422456741333)\n",
      "('summus', 0.6167148947715759)\n",
      "('error', 0.6144319772720337)\n",
      "('timor', 0.6143274307250977)\n",
      "('furor', 0.5890376567840576)\n",
      "('nullus', 0.5875043869018555)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('pudor', 0.660911500453949)\n",
      "('error', 0.6432291269302368)\n",
      "('furor', 0.6004754304885864)\n",
      "('timor', 0.5997322797775269)\n",
      "('expers', 0.5990047454833984)\n",
      "('amicior', 0.5953745245933533)\n",
      "('salutaris', 0.5937305688858032)\n",
      "('dolor', 0.5898163318634033)\n",
      "('mortalis', 0.5780104398727417)\n",
      "('gemitus', 0.5755825042724609)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('caritas', 0.6510095596313477)\n",
      "('pietas1', 0.6259500980377197)\n",
      "('fidelitas', 0.6227724552154541)\n",
      "('industria1', 0.6189290881156921)\n",
      "('humanitas', 0.6177335381507874)\n",
      "('amo', 0.6047547459602356)\n",
      "('laetitia', 0.604009747505188)\n",
      "('desiderium', 0.5951753854751587)\n",
      "('misericordia', 0.5874444246292114)\n",
      "('obseruantia', 0.5855789184570312)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('caritas', 0.6774085760116577)\n",
      "('fidelitas', 0.6700564622879028)\n",
      "('liberalitas', 0.6683306694030762)\n",
      "('constantia1', 0.6632899045944214)\n",
      "('industria1', 0.6600381135940552)\n",
      "('beneuolens', 0.6542344093322754)\n",
      "('cupiditas', 0.6538186073303223)\n",
      "('beneuolentia', 0.6479369401931763)\n",
      "('humanitas', 0.6472976207733154)\n",
      "('continentia1', 0.6454772353172302)\n",
      "\n",
      "\u001b[31mpudor\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('furor', 0.6761273145675659)\n",
      "('amor', 0.6753295063972473)\n",
      "('tantus', 0.6703683137893677)\n",
      "('dolor', 0.6549620032310486)\n",
      "('metus', 0.6549262404441833)\n",
      "('timor', 0.6540335416793823)\n",
      "('constans', 0.6394664645195007)\n",
      "('pietas', 0.6202282905578613)\n",
      "('cupiditas', 0.6168038845062256)\n",
      "('pudoris', 0.6138365864753723)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('timor', 0.732406497001648)\n",
      "('metus', 0.7207092046737671)\n",
      "('amor', 0.6609115600585938)\n",
      "('furor', 0.6386967897415161)\n",
      "('dolor', 0.6124858260154724)\n",
      "('ambitio', 0.6066770553588867)\n",
      "('famae', 0.6056605577468872)\n",
      "('pietas', 0.5939763784408569)\n",
      "('honos', 0.5921438336372375)\n",
      "('honor', 0.5903384685516357)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('uerecundia', 0.7423039674758911)\n",
      "('misericordia', 0.6638351082801819)\n",
      "('integritas', 0.6627805233001709)\n",
      "('acerbitas', 0.6565795540809631)\n",
      "('innocentia', 0.6536427736282349)\n",
      "('recordatio', 0.6526570320129395)\n",
      "('existimatio', 0.6291780471801758)\n",
      "('dedecus', 0.6274505853652954)\n",
      "('continentia1', 0.6274327039718628)\n",
      "('angor', 0.6252697706222534)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('timor', 0.6885049343109131)\n",
      "('modestia', 0.6727569103240967)\n",
      "('ignominia', 0.657335102558136)\n",
      "('sollicitudo', 0.6540583968162537)\n",
      "('audacia', 0.6486248970031738)\n",
      "('metus', 0.6347575187683105)\n",
      "('innocentia', 0.6325951814651489)\n",
      "('laetitia', 0.6312640905380249)\n",
      "('superbia', 0.6284981966018677)\n",
      "('pertinacia', 0.6241970658302307)\n",
      "\n",
      "\u001b[31mcano\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('cerno', 0.8293197154998779)\n",
      "('mauors', 0.8207893371582031)\n",
      "('gubernas', 0.8063743114471436)\n",
      "('saeuo', 0.8040675520896912)\n",
      "('marsa', 0.8025188446044922)\n",
      "('manis', 0.7998283505439758)\n",
      "('aeacides', 0.7950549125671387)\n",
      "('dominamque', 0.7944770455360413)\n",
      "('caneret', 0.7943785190582275)\n",
      "('dumosa', 0.789914608001709)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('phoebique', 0.8140095472335815)\n",
      "('maeret', 0.8085440993309021)\n",
      "('erroresque', 0.8063466548919678)\n",
      "('daunia', 0.8059276342391968)\n",
      "('iugali', 0.804838240146637)\n",
      "('infernae', 0.8045039772987366)\n",
      "('uulcania', 0.8004024028778076)\n",
      "('hennaea', 0.7992514371871948)\n",
      "('bellona', 0.7981433868408203)\n",
      "('diuae', 0.7978883981704712)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('disseco', 0.5972294807434082)\n",
      "('ursinus', 0.590910017490387)\n",
      "('aspidas', 0.5873568058013916)\n",
      "('spasticus', 0.5741567611694336)\n",
      "('iocur', 0.5634351968765259)\n",
      "('albico', 0.5632373690605164)\n",
      "('saepiae', 0.5574640035629272)\n",
      "('orthopnoea', 0.5570926070213318)\n",
      "('uomitio', 0.5564547777175903)\n",
      "('plumo', 0.5556727647781372)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('saepiae', 0.5535014271736145)\n",
      "('mordeo', 0.5460636615753174)\n",
      "('cacoëthe', 0.538771390914917)\n",
      "('paralyticus', 0.5361864566802979)\n",
      "('tibia', 0.5284138917922974)\n",
      "('creber', 0.5214587450027466)\n",
      "('tuba', 0.5202218294143677)\n",
      "('potae', 0.5200856328010559)\n",
      "('melleus', 0.5194711685180664)\n",
      "('aspidas', 0.5125600099563599)\n",
      "\n",
      "\u001b[31mdignitas\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('salus', 0.7925768494606018)\n",
      "('exspectatio', 0.7666434645652771)\n",
      "('laus', 0.7558329105377197)\n",
      "('amplitudo', 0.7550672292709351)\n",
      "('improbitate', 0.7334187030792236)\n",
      "('auctoritas', 0.7301638126373291)\n",
      "('perturbatio', 0.72828608751297)\n",
      "('grauitas', 0.7250840663909912)\n",
      "('modestia', 0.7243483066558838)\n",
      "('existimatio', 0.7238847613334656)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('auctoritas', 0.800384521484375)\n",
      "('existimatio', 0.7966275811195374)\n",
      "('seueritas', 0.7812765836715698)\n",
      "('exspectatio', 0.7726461887359619)\n",
      "('laus', 0.7702658176422119)\n",
      "('uoluntas', 0.7515003681182861)\n",
      "('humanitas', 0.7514716386795044)\n",
      "('salus', 0.7391500473022461)\n",
      "('incredibilis', 0.7361450791358948)\n",
      "('cupiditas', 0.7345121502876282)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('obseruantia', 0.7202469706535339)\n",
      "('amplifico', 0.7043325901031494)\n",
      "('auctoritas', 0.6831585168838501)\n",
      "('humanitas', 0.6803106069564819)\n",
      "('existimatio', 0.6800454258918762)\n",
      "('utilitas', 0.6683915853500366)\n",
      "('liberalitas', 0.667622447013855)\n",
      "('integritas', 0.6672674417495728)\n",
      "('honoro', 0.6635590195655823)\n",
      "('honestas', 0.6613738536834717)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('utilitas', 0.7155566215515137)\n",
      "('amplitudo', 0.7129768133163452)\n",
      "('auctoritas', 0.7017154693603516)\n",
      "('officium', 0.7006381750106812)\n",
      "('laus', 0.7001360058784485)\n",
      "('existimatio', 0.6931731700897217)\n",
      "('humanitas', 0.689584493637085)\n",
      "('industria1', 0.6870406866073608)\n",
      "('constantia1', 0.6846284866333008)\n",
      "('liberalitas', 0.6801716089248657)\n",
      "\n",
      "\u001b[31mcarus\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('carissimus', 0.7806285619735718)\n",
      "('inimicus', 0.7400111556053162)\n",
      "('unicus', 0.7288075685501099)\n",
      "('uostra', 0.7263939380645752)\n",
      "('disertus', 0.7260253429412842)\n",
      "('superstes', 0.7259462475776672)\n",
      "('maxumo', 0.7224482297897339)\n",
      "('fuisti', 0.7199738621711731)\n",
      "('pessume', 0.7066649794578552)\n",
      "('curares', 0.7026439905166626)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('inimicus', 0.739293098449707)\n",
      "('fidelis', 0.714043378829956)\n",
      "('sollicitus', 0.7064939141273499)\n",
      "('expertus', 0.6952502727508545)\n",
      "('adflicto', 0.6927560567855835)\n",
      "('dignior', 0.6921035051345825)\n",
      "('cognitus', 0.682728111743927)\n",
      "('carissimus', 0.6823166608810425)\n",
      "('iucundus', 0.6813641786575317)\n",
      "('paéne', 0.6810204982757568)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('beneuolens', 0.6690277457237244)\n",
      "('unicus', 0.6656185388565063)\n",
      "('amicus', 0.6061148643493652)\n",
      "('chrysalus', 0.605015754699707)\n",
      "('erga', 0.6041693687438965)\n",
      "('impertio', 0.5876685976982117)\n",
      "('fidelitas', 0.5869717001914978)\n",
      "('mei', 0.585202693939209)\n",
      "('meum', 0.5791078209877014)\n",
      "('maleuolens', 0.5764033794403076)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('unicus', 0.665686309337616)\n",
      "('iucundus', 0.6264019012451172)\n",
      "('erga', 0.6138663291931152)\n",
      "('beneuolens', 0.6121461391448975)\n",
      "('gratus', 0.601753830909729)\n",
      "('fidelitas', 0.5952837467193604)\n",
      "('fidelis', 0.5939009189605713)\n",
      "('tulliae', 0.5762821435928345)\n",
      "('morigeror', 0.5726955533027649)\n",
      "('illíus', 0.5708804130554199)\n",
      "\n",
      "\u001b[31mamo\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('ecastor', 0.8796558380126953)\n",
      "('amas', 0.8678163886070251)\n",
      "('mones', 0.8536465167999268)\n",
      "('egone', 0.8366082906723022)\n",
      "('hau', 0.8343548774719238)\n",
      "('praedicas', 0.8326777219772339)\n",
      "('chreme', 0.8296623229980469)\n",
      "('pol', 0.8288089036941528)\n",
      "('érgo', 0.8258687853813171)\n",
      "('séd', 0.8233115077018738)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('rogem', 0.846319317817688)\n",
      "('lubens', 0.8452644348144531)\n",
      "('uah', 0.843443751335144)\n",
      "('egŏn', 0.8251186609268188)\n",
      "('mones', 0.8201998472213745)\n",
      "('flocci', 0.8186986446380615)\n",
      "('amas', 0.8186036348342896)\n",
      "('laudo', 0.817556619644165)\n",
      "('pereo', 0.8142061829566956)\n",
      "('tĕ', 0.8137155771255493)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('diligo', 0.6319265365600586)\n",
      "('amor', 0.6047547459602356)\n",
      "('suauis', 0.5838252902030945)\n",
      "('Hercules', 0.5677302479743958)\n",
      "('efflictim', 0.5412902235984802)\n",
      "('carus1', 0.5369195938110352)\n",
      "('studiosus', 0.5256444215774536)\n",
      "('odi', 0.5175546407699585)\n",
      "('dĭ', 0.5165680646896362)\n",
      "('inuideo', 0.5096327662467957)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('odi', 0.6054990291595459)\n",
      "('diligo', 0.6039066314697266)\n",
      "('gaudeo', 0.5906010866165161)\n",
      "('doleo', 0.5849798917770386)\n",
      "('inuideo', 0.58259117603302)\n",
      "('amor', 0.5787540078163147)\n",
      "('dicaearchum', 0.5659167766571045)\n",
      "('amicus1', 0.5599449276924133)\n",
      "('cupidus', 0.5485079288482666)\n",
      "('amicus', 0.5430886745452881)\n",
      "\n",
      "\u001b[31mscribo\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('respondeo', 0.8407977819442749)\n",
      "('lubenter', 0.8213809132575989)\n",
      "('adiuuas', 0.813746452331543)\n",
      "('postulo', 0.8095426559448242)\n",
      "('brute', 0.8057581186294556)\n",
      "('nuntias', 0.8032202124595642)\n",
      "('consulerem', 0.79737788438797)\n",
      "('credebam', 0.7953127026557922)\n",
      "('committam', 0.7945393323898315)\n",
      "('scripseram', 0.7916288375854492)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('scribam', 0.8057434558868408)\n",
      "('scriberem', 0.7992566227912903)\n",
      "('lubenter', 0.7968277335166931)\n",
      "('exspectabam', 0.7848657369613647)\n",
      "('gaudeam', 0.7732451558113098)\n",
      "('adsequar', 0.7726513147354126)\n",
      "('intellegis', 0.7708001136779785)\n",
      "('facio', 0.7674623131752014)\n",
      "('brute', 0.765916645526886)\n",
      "('persuade', 0.7644809484481812)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('liber4', 0.6220735907554626)\n",
      "('fadio', 0.568870484828949)\n",
      "('libra', 0.567691445350647)\n",
      "('littera', 0.5584113597869873)\n",
      "('magniloquentia', 0.5575917959213257)\n",
      "('balbus1', 0.5565413236618042)\n",
      "('loquor', 0.5523605346679688)\n",
      "('buthroto', 0.550958514213562)\n",
      "('turranio', 0.5499093532562256)\n",
      "('epistula', 0.5437573790550232)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('philotimum', 0.6637271642684937)\n",
      "('liber4', 0.6368970274925232)\n",
      "('epistula', 0.5827207565307617)\n",
      "('littera', 0.576386570930481)\n",
      "('philotimo', 0.5750860571861267)\n",
      "('philogenes', 0.5607917308807373)\n",
      "('philotimi', 0.5528125762939453)\n",
      "('coniectanea', 0.5488808155059814)\n",
      "('oppium', 0.5451489090919495)\n",
      "('loquor', 0.5436742305755615)\n",
      "\n",
      "\u001b[31mfacio\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('cures', 0.8110052943229675)\n",
      "('postulo', 0.8057984113693237)\n",
      "('facias', 0.7908643484115601)\n",
      "('facis', 0.7853530645370483)\n",
      "('tute', 0.7809972763061523)\n",
      "('dixis', 0.7777658700942993)\n",
      "('cedo', 0.7767754197120667)\n",
      "('caue', 0.7738430500030518)\n",
      "('metuo', 0.7723498940467834)\n",
      "('catule', 0.7716257572174072)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('feci', 0.8097273111343384)\n",
      "('suscenseo', 0.7848771810531616)\n",
      "('adsequar', 0.7793256044387817)\n",
      "('exspectabam', 0.770606517791748)\n",
      "('scribo', 0.7674623131752014)\n",
      "('brute', 0.7636207342147827)\n",
      "('catule', 0.757321298122406)\n",
      "('faciam', 0.7539860606193542)\n",
      "('cupio', 0.7537655234336853)\n",
      "('effecero', 0.753574550151825)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('fio', 0.6308690905570984)\n",
      "('sum1', 0.6158057451248169)\n",
      "('dico2', 0.5920508503913879)\n",
      "('habeo', 0.580849289894104)\n",
      "('edo1', 0.514936089515686)\n",
      "('uerus', 0.5004220008850098)\n",
      "('sero1', 0.4947584271430969)\n",
      "('uideo', 0.4933662712574005)\n",
      "('uto', 0.48664236068725586)\n",
      "('ito', 0.4825040400028229)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('dico2', 0.6664252281188965)\n",
      "('fio', 0.6521978974342346)\n",
      "('sum1', 0.5840091705322266)\n",
      "('habeo', 0.573696494102478)\n",
      "('do', 0.5612642765045166)\n",
      "('edo1', 0.5520738363265991)\n",
      "('uideo', 0.5449216365814209)\n",
      "('ipse', 0.5223643779754639)\n",
      "('ito', 0.5134822130203247)\n",
      "('uerus', 0.5085045695304871)\n",
      "\n",
      "\u001b[31mlaus\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('grauitas', 0.7767825126647949)\n",
      "('exspectatio', 0.7622722387313843)\n",
      "('amplitudo', 0.7578041553497314)\n",
      "('dignitas', 0.7558329105377197)\n",
      "('ingeni', 0.7504878044128418)\n",
      "('memoria', 0.7502184510231018)\n",
      "('commendatio', 0.7450073957443237)\n",
      "('perturbatio', 0.7413634061813354)\n",
      "('contentio', 0.737472653388977)\n",
      "('uoluntas', 0.7345441579818726)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('dignitas', 0.7702658176422119)\n",
      "('commendatio', 0.7273139357566833)\n",
      "('uirtus', 0.7205942869186401)\n",
      "('prudentia', 0.7164344787597656)\n",
      "('gloria', 0.7120715379714966)\n",
      "('opinio', 0.709394097328186)\n",
      "('auctoritas', 0.7079125642776489)\n",
      "('perturbatio', 0.7022783160209656)\n",
      "('disciplina', 0.7003540992736816)\n",
      "('aequabilitas', 0.6998453140258789)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('gloria', 0.771682858467102)\n",
      "('glorior', 0.7458114624023438)\n",
      "('honor', 0.7177746295928955)\n",
      "('laudo', 0.6704500913619995)\n",
      "('uirtus', 0.6648865342140198)\n",
      "('studium', 0.6610381603240967)\n",
      "('amplifico', 0.6564853191375732)\n",
      "('industria1', 0.6444457769393921)\n",
      "('continentia1', 0.6377541422843933)\n",
      "('admirabilis', 0.6353957056999207)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('glorior', 0.7771285772323608)\n",
      "('uirtus', 0.738848090171814)\n",
      "('honor', 0.7327480316162109)\n",
      "('industria1', 0.7065572738647461)\n",
      "('dignitas', 0.7001360654830933)\n",
      "('gloria', 0.6975167989730835)\n",
      "('honesto', 0.663180947303772)\n",
      "('eloquentia', 0.6575205326080322)\n",
      "('studium', 0.6395516991615295)\n",
      "('praestantia', 0.6373633146286011)\n",
      "\n",
      "\u001b[31mindustria\u001b[0m\n",
      "\u001b[34munlemmatized_no_stops\u001b[0m\n",
      "('diligentia', 0.7460492849349976)\n",
      "('improbitate', 0.7443936467170715)\n",
      "('prudentia', 0.7122471332550049)\n",
      "('laetitia', 0.7083171606063843)\n",
      "('constantia', 0.700203537940979)\n",
      "('amplitudo', 0.7001898288726807)\n",
      "('egeremus', 0.6970213055610657)\n",
      "('accurata', 0.6963273286819458)\n",
      "('improborum', 0.6960404515266418)\n",
      "('utilitate', 0.68989497423172)\n",
      "\u001b[34munlemmatized_yes_stops\u001b[0m\n",
      "('improbitate', 0.6982171535491943)\n",
      "('integritate', 0.6909976601600647)\n",
      "('auaritia', 0.6664460897445679)\n",
      "('moderatione', 0.66603684425354)\n",
      "('grauitate', 0.6607422232627869)\n",
      "('amicitia', 0.644286036491394)\n",
      "('dignitate', 0.6398682594299316)\n",
      "('temperantia', 0.6375774145126343)\n",
      "('audacia', 0.6358821988105774)\n",
      "('honestate', 0.6348168849945068)\n",
      "\u001b[34mlemmatized_no_stops\u001b[0m\n",
      "('fidelitas', 0.8541709184646606)\n",
      "('continentia1', 0.8309833407402039)\n",
      "('integritas', 0.8097890019416809)\n",
      "('constantia1', 0.8040812015533447)\n",
      "('liberalitas', 0.8011647462844849)\n",
      "('adiumentum', 0.8009836673736572)\n",
      "('amplifico', 0.7980403304100037)\n",
      "('antepono', 0.7889832258224487)\n",
      "('beneuolentia', 0.7887541055679321)\n",
      "('beneuolens', 0.7876464128494263)\n",
      "\u001b[34mlemmatized_yes_stops\u001b[0m\n",
      "('constantia1', 0.826846182346344)\n",
      "('prudentia', 0.7952827215194702)\n",
      "('continentia1', 0.787614643573761)\n",
      "('beneuolentia', 0.7848294973373413)\n",
      "('integritas', 0.7819041013717651)\n",
      "('diligentia', 0.7639070153236389)\n",
      "('probitas', 0.7569852471351624)\n",
      "('amplifico', 0.7569388151168823)\n",
      "('commendatio', 0.7565748691558838)\n",
      "('liberalitas', 0.7520667314529419)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sims(word_all_models_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_paths = {'lemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_greek_lemmatizer_stops.model',\n",
    "                'lemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_greek_lemmatizer.model',\n",
    "                'unlemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_greek_stops.model',\n",
    "                'unlemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_greek.model'}\n",
    "\n",
    "save_dir = '~/cltk_data/user_data/word2vec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kyle/cltk_data/user_data/word2vec/w2v_greek_lemmatizer_stops.model.syn0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a3cc7b2670a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/cltk_data/user_data/word2vec/w2v_greek_lemmatizer_stops.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kyle/cltk/venv/lib/python3.4/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kyle/cltk/venv/lib/python3.4/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kyle/cltk_data/user_data/word2vec/w2v_greek_lemmatizer_stops.model.syn0.npy'"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(os.path.expanduser('~/cltk_data/user_data/word2vec/w2v_greek_lemmatizer_stops.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'ἄγγελος1' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-940d7bd97fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ἄγγελος1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kyle/cltk/venv/lib/python3.4/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'ἄγγελος1' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.most_similar('ἄγγελος')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_all_models_list = defaultdict(list)\n",
    "for model_name, model_path in models_paths.items():\n",
    "\n",
    "    # setup paths\n",
    "    model_path = os.path.expanduser(model_path)\n",
    "    save_dir = os.path.expanduser(save_dir)\n",
    "    save_file = os.path.join(save_dir, model_name)\n",
    "\n",
    "    model = Word2Vec.load(model_path)\n",
    "\n",
    "    words = ['amicitia', ('carus', 'carus1'), 'dignitas', 'amo', 'amor', ('industria', 'industria1'), 'facio', 'laus', 'scribo', 'cano', 'pudor']\n",
    "    for word in words:\n",
    "        if type(word) is str:\n",
    "            headword, sims = get_sims(model_name, word)\n",
    "        elif type(word) is tuple:\n",
    "            headword, sims = get_sims(model_name, word[0], word[1])\n",
    "        word_all_models_list[headword].append((model_name, sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
