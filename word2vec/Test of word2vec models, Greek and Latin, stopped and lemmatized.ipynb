{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a qualitative test of results returned by word2vec models generated by means of the CLTK and gensim's implementation of the algorithm. There are four models for Latin and Greek each, with the following parameters:\n",
    "\n",
    "* lemmatized and stopwords removed\n",
    "* lemmatized \n",
    "* stopwords removed\n",
    "* plaintext (ie, not lemmatized nor stopwords removed)\n",
    "\n",
    "All the models were build with `Word2Vec()` arguments `size=100`, `window=5`, and `min_count=5`. The code made to generate these is in notebook </word2vec_build_model_phi5_tlg_test>. It was run on a remote server [with this setup code](https://github.com/kylepjohnson/cltk_remote_setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_paths = {'lemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_latin_lemmatizer_stops.model',\n",
    "                'lemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_latin_lemmatizer.model',\n",
    "                'unlemmatized_no_stops': '~/cltk_data/user_data/word2vec/w2v_latin_stops.model',\n",
    "                'unlemmatized_yes_stops': '~/cltk_data/user_data/word2vec/w2v_latin.model'}\n",
    "\n",
    "save_dir = '~/cltk_data/user_data/word2vec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "def get_sims(model_name, word_1, word_2=None):\n",
    "    word = word_1\n",
    "    if word_2 and model_name in ['lemmatized_no_stops', 'lemmatized_yes_stops']:\n",
    "        word = word_2\n",
    "    return word_1, model.most_similar(word)\n",
    "\n",
    "sims_dict = {}\n",
    "for model_name, model_path in models_paths.items():\n",
    "    \n",
    "    # setup paths\n",
    "    model_path = os.path.expanduser(model_path)\n",
    "    save_dir = os.path.expanduser(save_dir)\n",
    "    save_file = os.path.join(save_dir, model_name)\n",
    "    \n",
    "    model = Word2Vec.load(model_path)\n",
    "    #print(colored(model_name, 'blue'))\n",
    "    #print(model)\n",
    "\n",
    "    sims_list = []\n",
    "    words = ['amicitia', ('carus', 'carus1'), 'dignitas', 'amo', 'amor', ('industria', 'industria1'), \n",
    "             'facio', 'laus', 'scribo', 'cano', 'pudor']\n",
    "    for word in words:\n",
    "        if type(word) is str:\n",
    "            sims = get_sims(model_name, word)\n",
    "        elif type(word) is tuple:\n",
    "            sims = get_sims(model_name, word[0], word[1])\n",
    "        sims_list.append(sims)\n",
    "    sims_dict[model_name] = sims_list\n",
    "\n",
    "    '''\n",
    "    # rm file if already exists\n",
    "    if os.path.isfile(save_file):\n",
    "        os.remove(save_file)\n",
    "    \n",
    "    # write contents\n",
    "    with open(save_file, 'w') as file_open:\n",
    "        file_open.write('')\n",
    "    '''\n",
    "\n",
    "#! start here\n",
    "# make a dict like:\n",
    "# {'amicitia': {'lemmatized_no_stops': [('benuolentia': 0.8302, ...), ...]}\n",
    "headword_dict = {}\n",
    "for model_type in sims_dict:\n",
    "    pairs = sims_dict[model_type]\n",
    "    sims_dict = defaultdict(list)\n",
    "    for pair in pairs:\n",
    "        sims_vals = (model_type, pair[1])\n",
    "        sims_dict[pair[0]].append(sims_vals)\n",
    "    headword_dict[] = (model_type, pair[1])\n",
    "\n",
    "print(headword_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
